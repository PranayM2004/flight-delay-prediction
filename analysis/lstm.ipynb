{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OP_CARRIER  OP_CARRIER_FL_NUM\n",
      "UA          1650                 762.0\n",
      "F9          7306                 478.0\n",
      "            2822                 389.0\n",
      "G4          5111                 355.0\n",
      "F9          1719                 339.0\n",
      "G4          2328                 316.0\n",
      "            2860                 310.0\n",
      "            2859                 292.0\n",
      "EV          5324                 279.0\n",
      "G4          5779                 264.0\n",
      "EV          5273                 207.0\n",
      "UA          2770                 206.0\n",
      "G4          5665                 199.0\n",
      "AS          282                  198.0\n",
      "EV          5322                 182.0\n",
      "G4          2304                 182.0\n",
      "OO          4106                 181.0\n",
      "            4218                 181.0\n",
      "EV          5307                 180.0\n",
      "            5280                 173.0\n",
      "            5347                 169.0\n",
      "G4          2305                 167.0\n",
      "            5441                 165.0\n",
      "            5105                 162.0\n",
      "EV          5267                 159.5\n",
      "F9          2725                 159.0\n",
      "EV          5266                 159.0\n",
      "AS          1671                 156.0\n",
      "G4          5104                 155.0\n",
      "            5815                 150.0\n",
      "NK          1847                 147.5\n",
      "F9          7206                 140.0\n",
      "G4          5483                 139.0\n",
      "EV          5342                 136.0\n",
      "            5264                 135.0\n",
      "G4          5799                 134.0\n",
      "            5586                 133.0\n",
      "            2870                 132.5\n",
      "            2871                 129.5\n",
      "NK          2069                 129.0\n",
      "EV          5275                 124.5\n",
      "NK          2068                 122.0\n",
      "F9          7074                 121.0\n",
      "EV          5318                 120.0\n",
      "            5380                 117.0\n",
      "NK          1859                 116.0\n",
      "F9          1881                 113.0\n",
      "UA          2833                 111.5\n",
      "G4          5778                 110.0\n",
      "            6758                 110.0\n",
      "Name: DEP_DELAY, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/Users/saianoopavunuri/Documents/cs_projects/flight_delay_prediction/2018.csv')\n",
    "top_10_groups = df.groupby(['OP_CARRIER', 'OP_CARRIER_FL_NUM'])['DEP_DELAY'].median()\n",
    "\n",
    "# Sort the groups by the calculated median in descending order and get the top 50\n",
    "top_10_groups = top_10_groups.sort_values(ascending=False).head(50)\n",
    "\n",
    "print(top_10_groups)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OP_CARRIER  OP_CARRIER_FL_NUM\n",
      "DL          2398                 14.0\n",
      "F9          1139                 12.0\n",
      "WN          38                   11.0\n",
      "B6          566                  11.0\n",
      "WN          483                   8.0\n",
      "UA          1551                  7.0\n",
      "WN          32                    7.0\n",
      "            42                    7.0\n",
      "            2263                  6.0\n",
      "F9          1702                  6.0\n",
      "WN          44                    6.0\n",
      "            878                   6.0\n",
      "            63                    6.0\n",
      "            160                   6.0\n",
      "            2016                  6.0\n",
      "            674                   6.0\n",
      "            406                   5.5\n",
      "            696                   5.0\n",
      "            707                   5.0\n",
      "            757                   5.0\n",
      "            287                   5.0\n",
      "            285                   5.0\n",
      "            780                   5.0\n",
      "            1814                  5.0\n",
      "            847                   5.0\n",
      "            48                    5.0\n",
      "            887                   5.0\n",
      "            974                   5.0\n",
      "            40                    5.0\n",
      "            1370                  5.0\n",
      "            1647                  5.0\n",
      "            31                    5.0\n",
      "            677                   5.0\n",
      "            55                    5.0\n",
      "DL          1942                  5.0\n",
      "UA          1983                  4.5\n",
      "AA          490                   4.5\n",
      "            457                   4.0\n",
      "DL          2142                  4.0\n",
      "WN          205                   4.0\n",
      "AA          556                   4.0\n",
      "WN          251                   4.0\n",
      "            1978                  4.0\n",
      "            611                   4.0\n",
      "            1889                  4.0\n",
      "UA          665                   4.0\n",
      "WN          197                   4.0\n",
      "            1807                  4.0\n",
      "            1669                  4.0\n",
      "            1525                  4.0\n",
      "Name: DEP_DELAY, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Group by 'OP_CARRIER' and 'OP_CARRIER_FL_NUM'\n",
    "grouped = df.groupby(['OP_CARRIER', 'OP_CARRIER_FL_NUM'])\n",
    "\n",
    "# Filter groups with a size of at least 10\n",
    "filtered_groups = grouped.filter(lambda x: len(x) >= 500)\n",
    "\n",
    "# Calculate the median of 'DEP_DELAY' for the filtered groups\n",
    "top_10_groups = filtered_groups.groupby(['OP_CARRIER', 'OP_CARRIER_FL_NUM'])['DEP_DELAY'].median()\n",
    "\n",
    "# Sort the groups by the calculated median in descending order and get the top 50\n",
    "top_10_groups = top_10_groups.sort_values(ascending=False).head(50)\n",
    "\n",
    "print(top_10_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "start_year = 2018\n",
    "end_year = 2018\n",
    "\n",
    "def get_df(carrier, flight_number, start_year, end_year, exclude=None):\n",
    "    ans = None\n",
    "    for year in range(start_year, end_year+1):\n",
    "        df = pd.read_csv(f\"/Users/saianoopavunuri/Documents/cs_projects/flight_delay_prediction/{year}.csv\")\n",
    "        if ans is None:\n",
    "            ans = df[(df['OP_CARRIER'] == carrier) & (df['OP_CARRIER_FL_NUM'] == flight_number)]\n",
    "            continue\n",
    "        ans = pd.concat([ans, df[(df['OP_CARRIER'] == carrier) & (df['OP_CARRIER_FL_NUM'] == flight_number)]])\n",
    "    \n",
    "    return ans\n",
    "\n",
    "\n",
    "SELECTED_OP_CARRIER = 'DL'\n",
    "SELECTED_FL_NUM = 2398\n",
    "\n",
    "# Combine multiple years for a single flight path\n",
    "df = get_df(SELECTED_OP_CARRIER, SELECTED_FL_NUM, start_year, end_year)\n",
    "\n",
    "# Combine multiple flights for a year\n",
    "# df = pd.read_csv('/Users/saianoopavunuri/Documents/cs_projects/flight_delay_prediction/2018.csv')\n",
    "\n",
    "# # Group by ORIGIN, DEST, and OP_CARRIER and count occurrences, then sort\n",
    "# top_50_groups = df.groupby(['ORIGIN', 'DEST', 'OP_CARRIER']).size().sort_values(ascending=False).head(10)\n",
    "\n",
    "# # Convert MultiIndex to a list of lists\n",
    "# routes = [list(idx) for idx in top_50_groups.index]\n",
    "\n",
    "# temp = pd.DataFrame()\n",
    "# for route in routes:\n",
    "#     origin, dest, carrier = route[0], route[1], route[2]\n",
    "#     temp = pd.concat([temp, df[(df['OP_CARRIER'] == carrier) & (df['ORIGIN'] == origin) & (df['DEST'] == dest)]])\n",
    "# df = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[(df['OP_CARRIER'] == SELECTED_OP_CARRIER) & (df['OP_CARRIER_FL_NUM'] == SELECTED_FL_NUM)]\n",
    "filtered_df = filtered_df.reset_index()\n",
    "\n",
    "filtered_df['DEP_DELAY'] = filtered_df['DEP_DELAY'].apply(lambda x: max(0,x))\n",
    "#filtered_df['DEP_DELAY'] = filtered_df['DEP_DELAY'].apply(lambda x: min(90,x))\n",
    "\n",
    "\n",
    "# Convert the time column to a string and format it\n",
    "filtered_df['CRS_DEP_TIME'] = filtered_df['CRS_DEP_TIME'].apply(lambda x: '{:04.0f}'.format(x))\n",
    "filtered_df['CRS_DEP_TIME'] = filtered_df['CRS_DEP_TIME'].str[:2] + ':' + filtered_df['CRS_DEP_TIME'].str[2:]\n",
    "\n",
    "# Combine date and time columns\n",
    "filtered_df['datetime'] = pd.to_datetime(filtered_df['FL_DATE'] + ' ' + filtered_df['CRS_DEP_TIME'])\n",
    "DROPPED_COLUMNS = ['CANCELLATION_CODE', 'CARRIER_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'LATE_AIRCRAFT_DELAY', 'Unnamed: 27', 'NAS_DELAY', 'CANCELLED', 'DIVERTED']\n",
    "filtered_df = filtered_df.drop(columns=DROPPED_COLUMNS)\n",
    "filtered_df.dropna(inplace=True)\n",
    "\n",
    "data = filtered_df.copy()\n",
    "# Convert the time column to a string and format it\n",
    "data['CRS_DEP_TIME'] = data['CRS_DEP_TIME'].apply(lambda x: x.replace(\":\",\"\")).astype(int).apply(lambda x: '{:04.0f}'.format(x))\n",
    "data['CRS_DEP_TIME'] = data['CRS_DEP_TIME'].str[:2] + ':' + data['CRS_DEP_TIME'].str[2:]\n",
    "\n",
    "# Combine date and time columns\n",
    "data['datetime'] = pd.to_datetime(data['FL_DATE'] + ' ' + data['CRS_DEP_TIME'])\n",
    "data = data.sort_values(by='datetime')\n",
    "data.reset_index(inplace=True)\n",
    "\n",
    "# Convert datetime to its components\n",
    "data['year'] = data['datetime'].dt.year\n",
    "data['month'] = data['datetime'].dt.month\n",
    "data['day'] = data['datetime'].dt.day\n",
    "data['hour'] = data['datetime'].dt.hour\n",
    "data['dayofweek'] = data['datetime'].dt.dayofweek  # Monday=0, Sunday=6\n",
    "\n",
    "# One-hot encode the time variables\n",
    "data = pd.get_dummies(data, columns=['month', 'day', 'hour', 'dayofweek'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>FL_DATE</th>\n",
       "      <th>OP_CARRIER</th>\n",
       "      <th>OP_CARRIER_FL_NUM</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>DEST</th>\n",
       "      <th>CRS_DEP_TIME</th>\n",
       "      <th>DEP_TIME</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>...</th>\n",
       "      <th>hour_16</th>\n",
       "      <th>hour_17</th>\n",
       "      <th>hour_18</th>\n",
       "      <th>dayofweek_0</th>\n",
       "      <th>dayofweek_1</th>\n",
       "      <th>dayofweek_2</th>\n",
       "      <th>dayofweek_3</th>\n",
       "      <th>dayofweek_4</th>\n",
       "      <th>dayofweek_5</th>\n",
       "      <th>dayofweek_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>25679</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>DL</td>\n",
       "      <td>2398</td>\n",
       "      <td>BZN</td>\n",
       "      <td>MSP</td>\n",
       "      <td>05:45</td>\n",
       "      <td>606.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>32517</td>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>DL</td>\n",
       "      <td>2398</td>\n",
       "      <td>BZN</td>\n",
       "      <td>MSP</td>\n",
       "      <td>05:45</td>\n",
       "      <td>549.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>54605</td>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>DL</td>\n",
       "      <td>2398</td>\n",
       "      <td>BZN</td>\n",
       "      <td>MSP</td>\n",
       "      <td>05:45</td>\n",
       "      <td>552.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>71004</td>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>DL</td>\n",
       "      <td>2398</td>\n",
       "      <td>BZN</td>\n",
       "      <td>MSP</td>\n",
       "      <td>05:45</td>\n",
       "      <td>550.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>81157</td>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>DL</td>\n",
       "      <td>2398</td>\n",
       "      <td>BZN</td>\n",
       "      <td>MSP</td>\n",
       "      <td>05:45</td>\n",
       "      <td>548.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>1167</td>\n",
       "      <td>7145874</td>\n",
       "      <td>2018-12-28</td>\n",
       "      <td>DL</td>\n",
       "      <td>2398</td>\n",
       "      <td>EWR</td>\n",
       "      <td>ATL</td>\n",
       "      <td>17:59</td>\n",
       "      <td>1827.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>1168</td>\n",
       "      <td>7160694</td>\n",
       "      <td>2018-12-29</td>\n",
       "      <td>DL</td>\n",
       "      <td>2398</td>\n",
       "      <td>ATL</td>\n",
       "      <td>EWR</td>\n",
       "      <td>15:02</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>1169</td>\n",
       "      <td>7160695</td>\n",
       "      <td>2018-12-29</td>\n",
       "      <td>DL</td>\n",
       "      <td>2398</td>\n",
       "      <td>EWR</td>\n",
       "      <td>ATL</td>\n",
       "      <td>17:59</td>\n",
       "      <td>1754.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>1170</td>\n",
       "      <td>7187114</td>\n",
       "      <td>2018-12-30</td>\n",
       "      <td>DL</td>\n",
       "      <td>2398</td>\n",
       "      <td>ATL</td>\n",
       "      <td>EWR</td>\n",
       "      <td>15:02</td>\n",
       "      <td>1546.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>1171</td>\n",
       "      <td>7187115</td>\n",
       "      <td>2018-12-30</td>\n",
       "      <td>DL</td>\n",
       "      <td>2398</td>\n",
       "      <td>EWR</td>\n",
       "      <td>ATL</td>\n",
       "      <td>17:59</td>\n",
       "      <td>1831.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1147 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      level_0    index     FL_DATE OP_CARRIER  OP_CARRIER_FL_NUM ORIGIN DEST  \\\n",
       "0           0    25679  2017-01-02         DL               2398    BZN  MSP   \n",
       "1           1    32517  2017-01-03         DL               2398    BZN  MSP   \n",
       "2           2    54605  2017-01-04         DL               2398    BZN  MSP   \n",
       "3           3    71004  2017-01-05         DL               2398    BZN  MSP   \n",
       "4           4    81157  2017-01-06         DL               2398    BZN  MSP   \n",
       "...       ...      ...         ...        ...                ...    ...  ...   \n",
       "1142     1167  7145874  2018-12-28         DL               2398    EWR  ATL   \n",
       "1143     1168  7160694  2018-12-29         DL               2398    ATL  EWR   \n",
       "1144     1169  7160695  2018-12-29         DL               2398    EWR  ATL   \n",
       "1145     1170  7187114  2018-12-30         DL               2398    ATL  EWR   \n",
       "1146     1171  7187115  2018-12-30         DL               2398    EWR  ATL   \n",
       "\n",
       "     CRS_DEP_TIME  DEP_TIME  DEP_DELAY  ...  hour_16  hour_17  hour_18  \\\n",
       "0           05:45     606.0       21.0  ...        0        0        0   \n",
       "1           05:45     549.0        4.0  ...        0        0        0   \n",
       "2           05:45     552.0        7.0  ...        0        0        0   \n",
       "3           05:45     550.0        5.0  ...        0        0        0   \n",
       "4           05:45     548.0        3.0  ...        0        0        0   \n",
       "...           ...       ...        ...  ...      ...      ...      ...   \n",
       "1142        17:59    1827.0       28.0  ...        0        1        0   \n",
       "1143        15:02    1500.0        0.0  ...        0        0        0   \n",
       "1144        17:59    1754.0        0.0  ...        0        1        0   \n",
       "1145        15:02    1546.0       44.0  ...        0        0        0   \n",
       "1146        17:59    1831.0       32.0  ...        0        1        0   \n",
       "\n",
       "      dayofweek_0  dayofweek_1  dayofweek_2  dayofweek_3  dayofweek_4  \\\n",
       "0               1            0            0            0            0   \n",
       "1               0            1            0            0            0   \n",
       "2               0            0            1            0            0   \n",
       "3               0            0            0            1            0   \n",
       "4               0            0            0            0            1   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "1142            0            0            0            0            1   \n",
       "1143            0            0            0            0            0   \n",
       "1144            0            0            0            0            0   \n",
       "1145            0            0            0            0            0   \n",
       "1146            0            0            0            0            0   \n",
       "\n",
       "      dayofweek_5  dayofweek_6  \n",
       "0               0            0  \n",
       "1               0            0  \n",
       "2               0            0  \n",
       "3               0            0  \n",
       "4               0            0  \n",
       "...           ...          ...  \n",
       "1142            0            0  \n",
       "1143            1            0  \n",
       "1144            1            0  \n",
       "1145            0            1  \n",
       "1146            0            1  \n",
       "\n",
       "[1147 rows x 80 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2t/mfs621pj7r38pl663d60tjmw0000gn/T/ipykernel_15921/994952462.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"floored_datetime\"] = data[\"datetime\"].dt.floor(\"H\")\n",
      "/var/folders/2t/mfs621pj7r38pl663d60tjmw0000gn/T/ipykernel_15921/994952462.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[feature] = data[\"floored_datetime\"].map(lambda x: weather_dict.get(x, {}).get(feature, None))\n",
      "/var/folders/2t/mfs621pj7r38pl663d60tjmw0000gn/T/ipykernel_15921/994952462.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[feature] = data[\"floored_datetime\"].map(lambda x: weather_dict.get(x, {}).get(feature, None))\n",
      "/var/folders/2t/mfs621pj7r38pl663d60tjmw0000gn/T/ipykernel_15921/994952462.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[feature] = data[\"floored_datetime\"].map(lambda x: weather_dict.get(x, {}).get(feature, None))\n",
      "/var/folders/2t/mfs621pj7r38pl663d60tjmw0000gn/T/ipykernel_15921/994952462.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[feature] = data[\"floored_datetime\"].map(lambda x: weather_dict.get(x, {}).get(feature, None))\n",
      "/var/folders/2t/mfs621pj7r38pl663d60tjmw0000gn/T/ipykernel_15921/994952462.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[feature] = data[\"floored_datetime\"].map(lambda x: weather_dict.get(x, {}).get(feature, None))\n",
      "/var/folders/2t/mfs621pj7r38pl663d60tjmw0000gn/T/ipykernel_15921/994952462.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.drop(columns=[\"floored_datetime\"], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "lat = 38.95\n",
    "long = -77.46\n",
    "response = requests.get(f'https://archive-api.open-meteo.com/v1/archive?latitude={lat}&longitude={long}&start_date={start_year}-01-01&end_date={end_year}-12-31&hourly=temperature_2m,rain,snowfall,cloudcover,windspeed_100m')\n",
    "weather = response.json()\n",
    "\n",
    "weather_dict = {}\n",
    "from datetime import datetime\n",
    "for i, date in enumerate(weather['hourly']['time']):\n",
    "    hour  = datetime.strptime(date, \"%Y-%m-%dT%H:%M\")\n",
    "    weather_dict[hour] = {'temperature_2m': weather['hourly']['temperature_2m'][i],'rain': weather['hourly']['rain'][i], 'snowfall': weather['hourly']['snowfall'][i], 'cloudcover': weather['hourly']['cloudcover'][i], 'windspeed_100m': weather['hourly']['windspeed_100m'][i] }\n",
    "\n",
    "# Floor the datetime to the nearest hour\n",
    "data[\"floored_datetime\"] = data[\"datetime\"].dt.floor(\"H\")\n",
    "\n",
    "# Look up the weather data and add new columns to the DataFrame\n",
    "for feature in ['temperature_2m', 'rain', 'snowfall', 'cloudcover', 'windspeed_100m']:\n",
    "    data[feature] = data[\"floored_datetime\"].map(lambda x: weather_dict.get(x, {}).get(feature, None))\n",
    "\n",
    "# Drop the 'floored_datetime' column if not needed\n",
    "data.drop(columns=[\"floored_datetime\"], inplace=True)\n",
    "data = data.sort_values(by='datetime')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1052.000000\n",
       "mean       45.260456\n",
       "std        71.021583\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%        21.000000\n",
       "75%        57.000000\n",
       "max       904.000000\n",
       "Name: DEP_DELAY, dtype: float64"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['DEP_DELAY'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EWR    526\n",
       "ATL    526\n",
       "Name: DEST, dtype: int64"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['DEST'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>FL_DATE</th>\n",
       "      <th>OP_CARRIER</th>\n",
       "      <th>OP_CARRIER_FL_NUM</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>DEST</th>\n",
       "      <th>CRS_DEP_TIME</th>\n",
       "      <th>DEP_TIME</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>...</th>\n",
       "      <th>dayofweek_3</th>\n",
       "      <th>dayofweek_4</th>\n",
       "      <th>dayofweek_5</th>\n",
       "      <th>dayofweek_6</th>\n",
       "      <th>DEP_CAT</th>\n",
       "      <th>temperature_2m</th>\n",
       "      <th>rain</th>\n",
       "      <th>snowfall</th>\n",
       "      <th>cloudcover</th>\n",
       "      <th>windspeed_100m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>692296</td>\n",
       "      <td>2017-02-17</td>\n",
       "      <td>DL</td>\n",
       "      <td>2398</td>\n",
       "      <td>ATL</td>\n",
       "      <td>EWR</td>\n",
       "      <td>15:15</td>\n",
       "      <td>1618.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60+</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>692297</td>\n",
       "      <td>2017-02-17</td>\n",
       "      <td>DL</td>\n",
       "      <td>2398</td>\n",
       "      <td>EWR</td>\n",
       "      <td>ATL</td>\n",
       "      <td>18:15</td>\n",
       "      <td>2157.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60+</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>729908</td>\n",
       "      <td>2017-02-20</td>\n",
       "      <td>DL</td>\n",
       "      <td>2398</td>\n",
       "      <td>ATL</td>\n",
       "      <td>EWR</td>\n",
       "      <td>15:15</td>\n",
       "      <td>1512.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0-15</td>\n",
       "      <td>13.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>729909</td>\n",
       "      <td>2017-02-20</td>\n",
       "      <td>DL</td>\n",
       "      <td>2398</td>\n",
       "      <td>EWR</td>\n",
       "      <td>ATL</td>\n",
       "      <td>18:15</td>\n",
       "      <td>1810.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0-15</td>\n",
       "      <td>16.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>749500</td>\n",
       "      <td>2017-02-21</td>\n",
       "      <td>DL</td>\n",
       "      <td>2398</td>\n",
       "      <td>ATL</td>\n",
       "      <td>EWR</td>\n",
       "      <td>15:15</td>\n",
       "      <td>1513.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0-15</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30</td>\n",
       "      <td>16.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>1167</td>\n",
       "      <td>7145874</td>\n",
       "      <td>2018-12-28</td>\n",
       "      <td>DL</td>\n",
       "      <td>2398</td>\n",
       "      <td>EWR</td>\n",
       "      <td>ATL</td>\n",
       "      <td>17:59</td>\n",
       "      <td>1827.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15-30</td>\n",
       "      <td>11.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>1168</td>\n",
       "      <td>7160694</td>\n",
       "      <td>2018-12-29</td>\n",
       "      <td>DL</td>\n",
       "      <td>2398</td>\n",
       "      <td>ATL</td>\n",
       "      <td>EWR</td>\n",
       "      <td>15:02</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0-15</td>\n",
       "      <td>10.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22</td>\n",
       "      <td>27.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>1169</td>\n",
       "      <td>7160695</td>\n",
       "      <td>2018-12-29</td>\n",
       "      <td>DL</td>\n",
       "      <td>2398</td>\n",
       "      <td>EWR</td>\n",
       "      <td>ATL</td>\n",
       "      <td>17:59</td>\n",
       "      <td>1754.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0-15</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22</td>\n",
       "      <td>31.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>1170</td>\n",
       "      <td>7187114</td>\n",
       "      <td>2018-12-30</td>\n",
       "      <td>DL</td>\n",
       "      <td>2398</td>\n",
       "      <td>ATL</td>\n",
       "      <td>EWR</td>\n",
       "      <td>15:02</td>\n",
       "      <td>1546.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30-60</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>1171</td>\n",
       "      <td>7187115</td>\n",
       "      <td>2018-12-30</td>\n",
       "      <td>DL</td>\n",
       "      <td>2398</td>\n",
       "      <td>EWR</td>\n",
       "      <td>ATL</td>\n",
       "      <td>17:59</td>\n",
       "      <td>1831.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30-60</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1052 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      level_0    index     FL_DATE OP_CARRIER  OP_CARRIER_FL_NUM ORIGIN DEST  \\\n",
       "45         45   692296  2017-02-17         DL               2398    ATL  EWR   \n",
       "46         46   692297  2017-02-17         DL               2398    EWR  ATL   \n",
       "48         48   729908  2017-02-20         DL               2398    ATL  EWR   \n",
       "49         49   729909  2017-02-20         DL               2398    EWR  ATL   \n",
       "50         50   749500  2017-02-21         DL               2398    ATL  EWR   \n",
       "...       ...      ...         ...        ...                ...    ...  ...   \n",
       "1142     1167  7145874  2018-12-28         DL               2398    EWR  ATL   \n",
       "1143     1168  7160694  2018-12-29         DL               2398    ATL  EWR   \n",
       "1144     1169  7160695  2018-12-29         DL               2398    EWR  ATL   \n",
       "1145     1170  7187114  2018-12-30         DL               2398    ATL  EWR   \n",
       "1146     1171  7187115  2018-12-30         DL               2398    EWR  ATL   \n",
       "\n",
       "     CRS_DEP_TIME  DEP_TIME  DEP_DELAY  ...  dayofweek_3  dayofweek_4  \\\n",
       "45          15:15    1618.0       63.0  ...            0            1   \n",
       "46          18:15    2157.0      222.0  ...            0            1   \n",
       "48          15:15    1512.0        0.0  ...            0            0   \n",
       "49          18:15    1810.0        0.0  ...            0            0   \n",
       "50          15:15    1513.0        0.0  ...            0            0   \n",
       "...           ...       ...        ...  ...          ...          ...   \n",
       "1142        17:59    1827.0       28.0  ...            0            1   \n",
       "1143        15:02    1500.0        0.0  ...            0            0   \n",
       "1144        17:59    1754.0        0.0  ...            0            0   \n",
       "1145        15:02    1546.0       44.0  ...            0            0   \n",
       "1146        17:59    1831.0       32.0  ...            0            0   \n",
       "\n",
       "      dayofweek_5  dayofweek_6  DEP_CAT  temperature_2m  rain  snowfall  \\\n",
       "45              0            0      60+             2.5   0.0       0.0   \n",
       "46              0            0      60+             7.9   0.0       0.0   \n",
       "48              0            0     0-15            13.7   0.0       0.0   \n",
       "49              0            0     0-15            16.4   0.0       0.0   \n",
       "50              0            0     0-15             8.0   0.0       0.0   \n",
       "...           ...          ...      ...             ...   ...       ...   \n",
       "1142            0            0    15-30            11.8   3.0       0.0   \n",
       "1143            1            0     0-15            10.7   0.0       0.0   \n",
       "1144            1            0     0-15            10.1   0.0       0.0   \n",
       "1145            0            1    30-60             4.2   0.0       0.0   \n",
       "1146            0            1    30-60             6.8   0.0       0.0   \n",
       "\n",
       "      cloudcover  windspeed_100m  \n",
       "45            20             4.8  \n",
       "46             2             4.7  \n",
       "48             0            21.4  \n",
       "49             0            19.0  \n",
       "50            30            16.9  \n",
       "...          ...             ...  \n",
       "1142         100            25.0  \n",
       "1143          22            27.1  \n",
       "1144          22            31.3  \n",
       "1145          63             7.7  \n",
       "1146          30             5.2  \n",
       "\n",
       "[1052 rows x 86 columns]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5859, 21)\n"
     ]
    }
   ],
   "source": [
    "# Function to remove outliers based on IQR\n",
    "def remove_outliers_iqr(df, column_name, lower_percentile=0.25, upper_percentile=0.75, threshold=1.5):\n",
    "    q1 = df[column_name].quantile(lower_percentile)\n",
    "    q3 = df[column_name].quantile(upper_percentile)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - threshold * iqr\n",
    "    upper_bound = q3 + threshold * iqr\n",
    "    df_filtered = df[(df[column_name] >= lower_bound) & (df[column_name] <= upper_bound)].copy()\n",
    "    return df_filtered\n",
    "\n",
    "\n",
    "# Specify the column name for which you want to remove outliers\n",
    "column_name = 'DEP_DELAY'\n",
    "\n",
    "# Remove outliers and get the cleaned DataFrame\n",
    "data = remove_outliers_iqr(data, column_name)\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[(data['ORIGIN'] == 'IAD') & (data['DEST'] == 'DEN')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only look at days that had 3 flights\n",
    "\n",
    "mask = data.groupby('FL_DATE')['FL_DATE'].transform('size') > 1\n",
    "data = data[mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1052.000000\n",
       "mean       45.260456\n",
       "std        71.021583\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%        21.000000\n",
       "75%        57.000000\n",
       "max       904.000000\n",
       "Name: DEP_DELAY, dtype: float64"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['DEP_DELAY'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>FL_DATE</th>\n",
       "      <th>OP_CARRIER</th>\n",
       "      <th>OP_CARRIER_FL_NUM</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>DEST</th>\n",
       "      <th>CRS_DEP_TIME</th>\n",
       "      <th>DEP_TIME</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>...</th>\n",
       "      <th>hour_16</th>\n",
       "      <th>hour_17</th>\n",
       "      <th>hour_18</th>\n",
       "      <th>dayofweek_0</th>\n",
       "      <th>dayofweek_1</th>\n",
       "      <th>dayofweek_2</th>\n",
       "      <th>dayofweek_3</th>\n",
       "      <th>dayofweek_4</th>\n",
       "      <th>dayofweek_5</th>\n",
       "      <th>dayofweek_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>35224</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>DL</td>\n",
       "      <td>2398</td>\n",
       "      <td>ATL</td>\n",
       "      <td>EWR</td>\n",
       "      <td>14:52</td>\n",
       "      <td>1456.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>35225</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>DL</td>\n",
       "      <td>2398</td>\n",
       "      <td>EWR</td>\n",
       "      <td>ATL</td>\n",
       "      <td>17:42</td>\n",
       "      <td>1755.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>56607</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>DL</td>\n",
       "      <td>2398</td>\n",
       "      <td>ATL</td>\n",
       "      <td>EWR</td>\n",
       "      <td>15:34</td>\n",
       "      <td>1539.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>56608</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>DL</td>\n",
       "      <td>2398</td>\n",
       "      <td>EWR</td>\n",
       "      <td>ATL</td>\n",
       "      <td>18:45</td>\n",
       "      <td>1851.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>95122</td>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>DL</td>\n",
       "      <td>2398</td>\n",
       "      <td>ATL</td>\n",
       "      <td>EWR</td>\n",
       "      <td>15:34</td>\n",
       "      <td>1545.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>583</td>\n",
       "      <td>7145874</td>\n",
       "      <td>2018-12-28</td>\n",
       "      <td>DL</td>\n",
       "      <td>2398</td>\n",
       "      <td>EWR</td>\n",
       "      <td>ATL</td>\n",
       "      <td>17:59</td>\n",
       "      <td>1827.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>584</td>\n",
       "      <td>7160694</td>\n",
       "      <td>2018-12-29</td>\n",
       "      <td>DL</td>\n",
       "      <td>2398</td>\n",
       "      <td>ATL</td>\n",
       "      <td>EWR</td>\n",
       "      <td>15:02</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>585</td>\n",
       "      <td>7160695</td>\n",
       "      <td>2018-12-29</td>\n",
       "      <td>DL</td>\n",
       "      <td>2398</td>\n",
       "      <td>EWR</td>\n",
       "      <td>ATL</td>\n",
       "      <td>17:59</td>\n",
       "      <td>1754.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>586</td>\n",
       "      <td>7187114</td>\n",
       "      <td>2018-12-30</td>\n",
       "      <td>DL</td>\n",
       "      <td>2398</td>\n",
       "      <td>ATL</td>\n",
       "      <td>EWR</td>\n",
       "      <td>15:02</td>\n",
       "      <td>1546.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>587</td>\n",
       "      <td>7187115</td>\n",
       "      <td>2018-12-30</td>\n",
       "      <td>DL</td>\n",
       "      <td>2398</td>\n",
       "      <td>EWR</td>\n",
       "      <td>ATL</td>\n",
       "      <td>17:59</td>\n",
       "      <td>1831.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>540 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     level_0    index     FL_DATE OP_CARRIER  OP_CARRIER_FL_NUM ORIGIN DEST  \\\n",
       "1          1    35224  2018-01-02         DL               2398    ATL  EWR   \n",
       "2          2    35225  2018-01-02         DL               2398    EWR  ATL   \n",
       "3          3    56607  2018-01-03         DL               2398    ATL  EWR   \n",
       "4          4    56608  2018-01-03         DL               2398    EWR  ATL   \n",
       "5          7    95122  2018-01-05         DL               2398    ATL  EWR   \n",
       "..       ...      ...         ...        ...                ...    ...  ...   \n",
       "574      583  7145874  2018-12-28         DL               2398    EWR  ATL   \n",
       "575      584  7160694  2018-12-29         DL               2398    ATL  EWR   \n",
       "576      585  7160695  2018-12-29         DL               2398    EWR  ATL   \n",
       "577      586  7187114  2018-12-30         DL               2398    ATL  EWR   \n",
       "578      587  7187115  2018-12-30         DL               2398    EWR  ATL   \n",
       "\n",
       "    CRS_DEP_TIME  DEP_TIME  DEP_DELAY  ...  hour_16  hour_17  hour_18  \\\n",
       "1          14:52    1456.0        4.0  ...        0        0        0   \n",
       "2          17:42    1755.0       13.0  ...        0        1        0   \n",
       "3          15:34    1539.0        5.0  ...        0        0        0   \n",
       "4          18:45    1851.0        6.0  ...        0        0        1   \n",
       "5          15:34    1545.0       11.0  ...        0        0        0   \n",
       "..           ...       ...        ...  ...      ...      ...      ...   \n",
       "574        17:59    1827.0       28.0  ...        0        1        0   \n",
       "575        15:02    1500.0        0.0  ...        0        0        0   \n",
       "576        17:59    1754.0        0.0  ...        0        1        0   \n",
       "577        15:02    1546.0       44.0  ...        0        0        0   \n",
       "578        17:59    1831.0       32.0  ...        0        1        0   \n",
       "\n",
       "     dayofweek_0  dayofweek_1  dayofweek_2  dayofweek_3  dayofweek_4  \\\n",
       "1              0            1            0            0            0   \n",
       "2              0            1            0            0            0   \n",
       "3              0            0            1            0            0   \n",
       "4              0            0            1            0            0   \n",
       "5              0            0            0            0            1   \n",
       "..           ...          ...          ...          ...          ...   \n",
       "574            0            0            0            0            1   \n",
       "575            0            0            0            0            0   \n",
       "576            0            0            0            0            0   \n",
       "577            0            0            0            0            0   \n",
       "578            0            0            0            0            0   \n",
       "\n",
       "     dayofweek_5  dayofweek_6  \n",
       "1              0            0  \n",
       "2              0            0  \n",
       "3              0            0  \n",
       "4              0            0  \n",
       "5              0            0  \n",
       "..           ...          ...  \n",
       "574            0            0  \n",
       "575            1            0  \n",
       "576            1            0  \n",
       "577            0            1  \n",
       "578            0            1  \n",
       "\n",
       "[540 rows x 78 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2t/mfs621pj7r38pl663d60tjmw0000gn/T/ipykernel_15921/2317443605.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['DEP_CAT'] = data['DEP_DELAY'].apply(lambda x: '0-30' if x <= 30 else ('30-60' if x <= 60 else '60+'))\n"
     ]
    }
   ],
   "source": [
    "data['DEP_CAT'] = data['DEP_DELAY'].apply(lambda x: '0-30' if x <= 30 else ('30-60' if x <= 60 else '60+'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>FL_DATE</th>\n",
       "      <th>OP_CARRIER</th>\n",
       "      <th>OP_CARRIER_FL_NUM</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>DEST</th>\n",
       "      <th>CRS_DEP_TIME</th>\n",
       "      <th>DEP_TIME</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>...</th>\n",
       "      <th>hour_17</th>\n",
       "      <th>hour_18</th>\n",
       "      <th>dayofweek_0</th>\n",
       "      <th>dayofweek_1</th>\n",
       "      <th>dayofweek_2</th>\n",
       "      <th>dayofweek_3</th>\n",
       "      <th>dayofweek_4</th>\n",
       "      <th>dayofweek_5</th>\n",
       "      <th>dayofweek_6</th>\n",
       "      <th>DEP_CAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>35224</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>DL</td>\n",
       "      <td>2398</td>\n",
       "      <td>ATL</td>\n",
       "      <td>EWR</td>\n",
       "      <td>14:52</td>\n",
       "      <td>1456.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>35225</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>DL</td>\n",
       "      <td>2398</td>\n",
       "      <td>EWR</td>\n",
       "      <td>ATL</td>\n",
       "      <td>17:42</td>\n",
       "      <td>1755.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>56607</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>DL</td>\n",
       "      <td>2398</td>\n",
       "      <td>ATL</td>\n",
       "      <td>EWR</td>\n",
       "      <td>15:34</td>\n",
       "      <td>1539.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>56608</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>DL</td>\n",
       "      <td>2398</td>\n",
       "      <td>EWR</td>\n",
       "      <td>ATL</td>\n",
       "      <td>18:45</td>\n",
       "      <td>1851.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>95122</td>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>DL</td>\n",
       "      <td>2398</td>\n",
       "      <td>ATL</td>\n",
       "      <td>EWR</td>\n",
       "      <td>15:34</td>\n",
       "      <td>1545.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>583</td>\n",
       "      <td>7145874</td>\n",
       "      <td>2018-12-28</td>\n",
       "      <td>DL</td>\n",
       "      <td>2398</td>\n",
       "      <td>EWR</td>\n",
       "      <td>ATL</td>\n",
       "      <td>17:59</td>\n",
       "      <td>1827.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>584</td>\n",
       "      <td>7160694</td>\n",
       "      <td>2018-12-29</td>\n",
       "      <td>DL</td>\n",
       "      <td>2398</td>\n",
       "      <td>ATL</td>\n",
       "      <td>EWR</td>\n",
       "      <td>15:02</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>585</td>\n",
       "      <td>7160695</td>\n",
       "      <td>2018-12-29</td>\n",
       "      <td>DL</td>\n",
       "      <td>2398</td>\n",
       "      <td>EWR</td>\n",
       "      <td>ATL</td>\n",
       "      <td>17:59</td>\n",
       "      <td>1754.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>586</td>\n",
       "      <td>7187114</td>\n",
       "      <td>2018-12-30</td>\n",
       "      <td>DL</td>\n",
       "      <td>2398</td>\n",
       "      <td>ATL</td>\n",
       "      <td>EWR</td>\n",
       "      <td>15:02</td>\n",
       "      <td>1546.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30-60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>587</td>\n",
       "      <td>7187115</td>\n",
       "      <td>2018-12-30</td>\n",
       "      <td>DL</td>\n",
       "      <td>2398</td>\n",
       "      <td>EWR</td>\n",
       "      <td>ATL</td>\n",
       "      <td>17:59</td>\n",
       "      <td>1831.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30-60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>540 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     level_0    index     FL_DATE OP_CARRIER  OP_CARRIER_FL_NUM ORIGIN DEST  \\\n",
       "1          1    35224  2018-01-02         DL               2398    ATL  EWR   \n",
       "2          2    35225  2018-01-02         DL               2398    EWR  ATL   \n",
       "3          3    56607  2018-01-03         DL               2398    ATL  EWR   \n",
       "4          4    56608  2018-01-03         DL               2398    EWR  ATL   \n",
       "5          7    95122  2018-01-05         DL               2398    ATL  EWR   \n",
       "..       ...      ...         ...        ...                ...    ...  ...   \n",
       "574      583  7145874  2018-12-28         DL               2398    EWR  ATL   \n",
       "575      584  7160694  2018-12-29         DL               2398    ATL  EWR   \n",
       "576      585  7160695  2018-12-29         DL               2398    EWR  ATL   \n",
       "577      586  7187114  2018-12-30         DL               2398    ATL  EWR   \n",
       "578      587  7187115  2018-12-30         DL               2398    EWR  ATL   \n",
       "\n",
       "    CRS_DEP_TIME  DEP_TIME  DEP_DELAY  ...  hour_17  hour_18  dayofweek_0  \\\n",
       "1          14:52    1456.0        4.0  ...        0        0            0   \n",
       "2          17:42    1755.0       13.0  ...        1        0            0   \n",
       "3          15:34    1539.0        5.0  ...        0        0            0   \n",
       "4          18:45    1851.0        6.0  ...        0        1            0   \n",
       "5          15:34    1545.0       11.0  ...        0        0            0   \n",
       "..           ...       ...        ...  ...      ...      ...          ...   \n",
       "574        17:59    1827.0       28.0  ...        1        0            0   \n",
       "575        15:02    1500.0        0.0  ...        0        0            0   \n",
       "576        17:59    1754.0        0.0  ...        1        0            0   \n",
       "577        15:02    1546.0       44.0  ...        0        0            0   \n",
       "578        17:59    1831.0       32.0  ...        1        0            0   \n",
       "\n",
       "     dayofweek_1  dayofweek_2  dayofweek_3  dayofweek_4  dayofweek_5  \\\n",
       "1              1            0            0            0            0   \n",
       "2              1            0            0            0            0   \n",
       "3              0            1            0            0            0   \n",
       "4              0            1            0            0            0   \n",
       "5              0            0            0            1            0   \n",
       "..           ...          ...          ...          ...          ...   \n",
       "574            0            0            0            1            0   \n",
       "575            0            0            0            0            1   \n",
       "576            0            0            0            0            1   \n",
       "577            0            0            0            0            0   \n",
       "578            0            0            0            0            0   \n",
       "\n",
       "     dayofweek_6  DEP_CAT  \n",
       "1              0     0-30  \n",
       "2              0     0-30  \n",
       "3              0     0-30  \n",
       "4              0     0-30  \n",
       "5              0     0-30  \n",
       "..           ...      ...  \n",
       "574            0     0-30  \n",
       "575            0     0-30  \n",
       "576            0     0-30  \n",
       "577            1    30-60  \n",
       "578            1    30-60  \n",
       "\n",
       "[540 rows x 79 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2t/mfs621pj7r38pl663d60tjmw0000gn/T/ipykernel_15921/2759450707.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['DEP_CAT'] = data['DEP_DELAY'].apply(lambda x: '0-15' if x <= 15 else ( '15-30' if  x <= 30 else ('30-60' if x <= 60 else '60+')))\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming 'data' has a 'DEP_CAT' column\n",
    "data['DEP_CAT'] = data['DEP_DELAY'].apply(lambda x: '0-15' if x <= 30 else ('30-60' if x <= 60 else '60+'))\n",
    "\n",
    "# Encoding the labels\n",
    "encoder = LabelEncoder()\n",
    "encoded_Y = encoder.fit_transform(data['DEP_CAT'])\n",
    "dummy_y = to_categorical(encoded_Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2t/mfs621pj7r38pl663d60tjmw0000gn/T/ipykernel_15921/1059635510.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['DEP_CAT'] = data['DEP_DELAY'].apply(lambda x: '0-15' if x <= 15 else ( '15-30' if  x <= 30 else ('30-60' if x <= 60 else '60+')))\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming 'data' has a 'DEP_CAT' column\n",
    "data['DEP_CAT'] = data['DEP_DELAY'].apply(lambda x: '0-15' if x <= 15 else ( '15-30' if  x <= 30 else ('30-60' if x <= 60 else '60+')))\n",
    "\n",
    "# Encoding the labels\n",
    "encoder = LabelEncoder()\n",
    "encoded_Y = encoder.fit_transform(data['DEP_CAT'])\n",
    "dummy_y = to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(features, target, window_size):\n",
    "    X, y = [], []\n",
    "    for i in range(0,len(features) - window_size, window_size+1):\n",
    "        X.append(features[i:i+window_size])\n",
    "        y.append(target[i+window_size])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "window_size = 1\n",
    "X, y = create_sequences(features.values, dummy_y, window_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7/7 [==============================] - 3s 88ms/step - loss: 1.3822 - accuracy: 0.3194 - val_loss: 1.3788 - val_accuracy: 0.4259\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.3704 - accuracy: 0.4213 - val_loss: 1.3693 - val_accuracy: 0.4259\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.3566 - accuracy: 0.4167 - val_loss: 1.3587 - val_accuracy: 0.4259\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.3377 - accuracy: 0.4167 - val_loss: 1.3461 - val_accuracy: 0.4259\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.3155 - accuracy: 0.4167 - val_loss: 1.3329 - val_accuracy: 0.4259\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.3006 - accuracy: 0.4167 - val_loss: 1.3255 - val_accuracy: 0.4259\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.2940 - accuracy: 0.4167 - val_loss: 1.3262 - val_accuracy: 0.4259\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.2877 - accuracy: 0.4167 - val_loss: 1.3280 - val_accuracy: 0.4259\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.2852 - accuracy: 0.4167 - val_loss: 1.3280 - val_accuracy: 0.4259\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.2745 - accuracy: 0.4167 - val_loss: 1.3274 - val_accuracy: 0.4259\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.2660 - accuracy: 0.4167 - val_loss: 1.3283 - val_accuracy: 0.4259\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.2706 - accuracy: 0.4167 - val_loss: 1.3299 - val_accuracy: 0.4259\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.2646 - accuracy: 0.4167 - val_loss: 1.3312 - val_accuracy: 0.4259\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2622 - accuracy: 0.4167 - val_loss: 1.3324 - val_accuracy: 0.4259\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.2695 - accuracy: 0.4167 - val_loss: 1.3334 - val_accuracy: 0.4259\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2543 - accuracy: 0.4167 - val_loss: 1.3367 - val_accuracy: 0.4259\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2463 - accuracy: 0.4167 - val_loss: 1.3429 - val_accuracy: 0.4259\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2493 - accuracy: 0.4167 - val_loss: 1.3502 - val_accuracy: 0.4259\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2335 - accuracy: 0.4167 - val_loss: 1.3581 - val_accuracy: 0.4259\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.2307 - accuracy: 0.4167 - val_loss: 1.3676 - val_accuracy: 0.4259\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2314 - accuracy: 0.4167 - val_loss: 1.3764 - val_accuracy: 0.4259\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2143 - accuracy: 0.4167 - val_loss: 1.3882 - val_accuracy: 0.4259\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1987 - accuracy: 0.4167 - val_loss: 1.4008 - val_accuracy: 0.4259\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.1959 - accuracy: 0.4167 - val_loss: 1.4148 - val_accuracy: 0.4259\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.1982 - accuracy: 0.4167 - val_loss: 1.4251 - val_accuracy: 0.4259\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.1684 - accuracy: 0.4259 - val_loss: 1.4419 - val_accuracy: 0.4074\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.1690 - accuracy: 0.4213 - val_loss: 1.4475 - val_accuracy: 0.4074\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.1498 - accuracy: 0.4398 - val_loss: 1.4567 - val_accuracy: 0.4259\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1339 - accuracy: 0.4352 - val_loss: 1.4765 - val_accuracy: 0.4074\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1488 - accuracy: 0.4398 - val_loss: 1.4859 - val_accuracy: 0.3704\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1155 - accuracy: 0.4444 - val_loss: 1.4987 - val_accuracy: 0.3704\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.1071 - accuracy: 0.4491 - val_loss: 1.5192 - val_accuracy: 0.3704\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.0925 - accuracy: 0.4769 - val_loss: 1.5338 - val_accuracy: 0.3333\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.0959 - accuracy: 0.4630 - val_loss: 1.5389 - val_accuracy: 0.3333\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.0782 - accuracy: 0.4722 - val_loss: 1.5558 - val_accuracy: 0.3333\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.0414 - accuracy: 0.4769 - val_loss: 1.5850 - val_accuracy: 0.3148\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.0699 - accuracy: 0.4769 - val_loss: 1.5854 - val_accuracy: 0.3148\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.0373 - accuracy: 0.4722 - val_loss: 1.6208 - val_accuracy: 0.3148\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.0277 - accuracy: 0.5046 - val_loss: 1.6436 - val_accuracy: 0.3148\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.0053 - accuracy: 0.5046 - val_loss: 1.6358 - val_accuracy: 0.3519\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.0043 - accuracy: 0.5046 - val_loss: 1.6773 - val_accuracy: 0.3519\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.0070 - accuracy: 0.4815 - val_loss: 1.6546 - val_accuracy: 0.3889\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.9604 - accuracy: 0.5093 - val_loss: 1.6977 - val_accuracy: 0.3519\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.9724 - accuracy: 0.5509 - val_loss: 1.7272 - val_accuracy: 0.3148\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.9507 - accuracy: 0.5926 - val_loss: 1.7956 - val_accuracy: 0.3519\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.9493 - accuracy: 0.5463 - val_loss: 1.8174 - val_accuracy: 0.3704\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.9350 - accuracy: 0.5741 - val_loss: 1.7854 - val_accuracy: 0.3333\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.9366 - accuracy: 0.5972 - val_loss: 1.8133 - val_accuracy: 0.3148\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.9104 - accuracy: 0.5787 - val_loss: 1.8671 - val_accuracy: 0.2778\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.9035 - accuracy: 0.5972 - val_loss: 1.9178 - val_accuracy: 0.3148\n",
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Number of categories\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "num_categories = dummy_y.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(80, return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(50, return_sequences=False))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(num_categories, activation='softmax'))  # Change for classification\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])  # Change loss and metric\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), shuffle=False)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (3864407628.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[160], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(X_test[])\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "14/14 [==============================] - 5s 51ms/step - loss: 8892.9531 - val_loss: 6304.7842\n",
      "Epoch 2/20\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8852.4844 - val_loss: 6199.2661\n",
      "Epoch 3/20\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8508.5361 - val_loss: 5182.0566\n",
      "Epoch 4/20\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 6583.2397 - val_loss: 3279.3130\n",
      "Epoch 5/20\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5179.1348 - val_loss: 3425.3215\n",
      "Epoch 6/20\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4949.0537 - val_loss: 2797.3845\n",
      "Epoch 7/20\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4257.4023 - val_loss: 1928.3706\n",
      "Epoch 8/20\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 3200.5178 - val_loss: 1342.1838\n",
      "Epoch 9/20\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2877.1279 - val_loss: 1183.5388\n",
      "Epoch 10/20\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2664.6958 - val_loss: 1231.7289\n",
      "Epoch 11/20\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2495.8230 - val_loss: 1171.5750\n",
      "Epoch 12/20\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2258.3699 - val_loss: 1141.8562\n",
      "Epoch 13/20\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2052.2151 - val_loss: 1308.1771\n",
      "Epoch 14/20\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2404.7861 - val_loss: 1259.7637\n",
      "Epoch 15/20\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2550.0779 - val_loss: 1165.7855\n",
      "Epoch 16/20\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2270.6492 - val_loss: 1430.2343\n",
      "Epoch 17/20\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2278.7427 - val_loss: 1675.8794\n",
      "Epoch 18/20\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2578.9172 - val_loss: 1185.0059\n",
      "Epoch 19/20\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2259.8921 - val_loss: 1436.4465\n",
      "Epoch 20/20\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2040.1835 - val_loss: 1257.5990\n",
      "4/4 [==============================] - 1s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, Conv1D\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def create_sequences(data, window_size):\n",
    "    X, y = [], []\n",
    "    for i in range(0,len(data) - window_size, window_size+1):\n",
    "        X.append(data[i:i+window_size])\n",
    "        y.append(data[i+window_size, -1])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Using past 5 hours to predict the next hour's delay\n",
    "window_size = 1\n",
    "\n",
    "\n",
    "# features = data[['rain', 'windspeed_100m'] + [col for col in data.columns if 'month_' in col or 'day_' in col or 'hour_' in col or 'dayofweek_' in col]+ ['ARR_DELAY','DEP_DELAY']]\n",
    "features = data[[col for col in data.columns if 'month_' in col or 'day_' in col or 'hour_' in col or 'dayofweek_' in col] + ['rain','windspeed_100m'] ['DEP_DELAY']]\n",
    "\n",
    "X, y = create_sequences(features.values, window_size)\n",
    "#y = data['DEP_DELAY'].values[window_size:]\n",
    "\n",
    "# Reshape X for LSTM [samples, timesteps, features]\n",
    "X = X.reshape(X.shape[0], X.shape[1], features.shape[1])\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build LSTM model with Stacked layers\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True)) # Add return_sequences=True for stacking\n",
    "model.add(Dropout(0.3))\n",
    "# Second LSTM layer\n",
    "model.add(LSTM(80, return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(LSTM(80, return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Third LSTM layer\n",
    "model.add(LSTM(50, return_sequences=False))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test), shuffle=False)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Square Error (RMSE): 38.19451461935751\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "# Compute RMSE\n",
    "rmse = sqrt(mean_squared_error(y_pred, y_test))\n",
    "print(f\"Root Mean Square Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1731.8767 - val_loss: 2738.2188\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1647.0219 - val_loss: 2723.3596\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1575.6268 - val_loss: 2710.2766\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1510.6775 - val_loss: 2696.3921\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1444.5323 - val_loss: 2681.1382\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1370.9746 - val_loss: 2664.3721\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1286.0421 - val_loss: 2645.5813\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1195.8257 - val_loss: 2625.2141\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1103.4454 - val_loss: 2603.1477\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1009.7360 - val_loss: 2580.6519\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 923.2413 - val_loss: 2558.8496\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 843.1660 - val_loss: 2538.9495\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 779.6806 - val_loss: 2521.2771\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 737.0787 - val_loss: 2507.4954\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 713.2479 - val_loss: 2497.3938\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 702.2953 - val_loss: 2490.5923\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 697.4285 - val_loss: 2486.5105\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 694.1323 - val_loss: 2484.1521\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 690.5093 - val_loss: 2483.3691\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 686.7220 - val_loss: 2482.8606\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 683.2058 - val_loss: 2482.3594\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 680.1213 - val_loss: 2481.7180\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 677.3198 - val_loss: 2480.7932\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 674.5573 - val_loss: 2479.5393\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 671.6436 - val_loss: 2477.9077\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 668.5314 - val_loss: 2476.3140\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 665.2034 - val_loss: 2475.0027\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 661.7161 - val_loss: 2473.7610\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 658.1633 - val_loss: 2472.4121\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 654.5578 - val_loss: 2471.0493\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 650.9025 - val_loss: 2470.0500\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 647.2525 - val_loss: 2469.2234\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 643.6302 - val_loss: 2468.4307\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 640.0325 - val_loss: 2467.6514\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 636.3387 - val_loss: 2466.7837\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 632.5580 - val_loss: 2465.8860\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 628.7271 - val_loss: 2465.1477\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 624.7927 - val_loss: 2464.5254\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 620.7620 - val_loss: 2464.9399\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 616.6748 - val_loss: 2466.4661\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 612.4940 - val_loss: 2469.6042\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 608.2720 - val_loss: 2472.3281\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 604.0923 - val_loss: 2474.1326\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 599.9058 - val_loss: 2475.2036\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 595.6064 - val_loss: 2476.5989\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 591.3058 - val_loss: 2479.3745\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 586.7961 - val_loss: 2483.2014\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 582.8664 - val_loss: 2486.2466\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 578.0491 - val_loss: 2488.7888\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 573.3123 - val_loss: 2491.6829\n",
      "2/2 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def create_sequences(features, target, window_size):\n",
    "    X, y = [], []\n",
    "    for i in range(0, len(features) - window_size, 2):\n",
    "        X.append(features[i:i+window_size])\n",
    "        y.append(target[i + window_size])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Assuming 'data' is your DataFrame and it is already preprocessed\n",
    "# Define window size\n",
    "window_size = 1\n",
    "\n",
    "# Select features and target\n",
    "feature_columns = [col for col in data.columns if 'month_' in col or 'day_' in col or 'hour_' in col or 'dayofweek_' in col] + ['DEP_DELAY']\n",
    "features = data[feature_columns]\n",
    "target = data['DEP_DELAY']\n",
    "\n",
    "# Create sequences\n",
    "X, y = create_sequences(features.values, target.values, window_size)\n",
    "\n",
    "# Reshape X for Dense model [samples, features]\n",
    "X = X.reshape(X.shape[0], -1)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build a simple Dense model\n",
    "model = Sequential()\n",
    "model.add(Dense(50, input_dim=X_train.shape[1], activation='relu')) # First hidden layer\n",
    "model.add(Dense(30, activation='relu')) # Second hidden layer\n",
    "model.add(Dense(1)) # Output layer\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), shuffle=False)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.0 0.0 [15.424121]\n",
      "0.0 0.0 [1.1820358]\n",
      "45.0 40.0 [39.65768]\n",
      "30.0 21.0 [35.83004]\n",
      "56.0 64.0 [58.516212]\n",
      "0.0 12.0 [1.8756492]\n",
      "44.0 32.0 [37.46548]\n",
      "87.0 69.0 [126.345474]\n",
      "0.0 8.0 [0.8201962]\n",
      "0.0 0.0 [2.982733]\n"
     ]
    }
   ],
   "source": [
    "for index in range(10):\n",
    "    print(X_test[index,0,-1], y_test[index], y_pred[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sam = []\n",
    "y_sam = []\n",
    "y_same = []\n",
    "for index in range(len(X)):\n",
    "    x_sam.append(X[index,0,-1])\n",
    "    y_sam.append(y[index])\n",
    "    y_same.append(x_sam[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x_sam = np.array(x_sam).reshape(-1,1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_sam, y_sam, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model with the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Plotting\n",
    "plt.scatter(X_train, y_train, color='blue', label='Training data')\n",
    "plt.scatter(X_test, y_test, color='green', label='Testing data')\n",
    "plt.plot(X_test, y_pred, color='red', label='Prediction on test data')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Linear Regression with Train-Test Split')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Square Error (RMSE): 72.14880069097823\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "# Compute RMSE\n",
    "rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"Root Mean Square Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t = []\n",
    "for i in range(len(X_test)):\n",
    "    y_t.append(X_test[i,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Square Error (RMSE): 32.263096680377835\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "# Compute RMSE\n",
    "rmse = sqrt(mean_squared_error(y_t, y_test))\n",
    "print(f\"Root Mean Square Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  5.  0. 22.  0.  1.  7.  1.] [0.0, 0.0, 0.0, 5.0, 0.0, 22.0, 0.0, 1.0, 7.0, 1.0] [  4.   0.   0.   2.   1.  76.   4.   0. 295.   0.]\n"
     ]
    }
   ],
   "source": [
    "print(X_test[:10,-1], guess[:10], y_test[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 2-dimensional, but 3 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/saianoopavunuri/Documents/cs_projects/flight_delay_prediction/flight-delay-prediction/analysis/lstm.ipynb Cell 14\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/saianoopavunuri/Documents/cs_projects/flight_delay_prediction/flight-delay-prediction/analysis/lstm.ipynb#Y114sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(y_pred)):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/saianoopavunuri/Documents/cs_projects/flight_delay_prediction/flight-delay-prediction/analysis/lstm.ipynb#Y114sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mprint\u001b[39m(X_test[i,:,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], y_pred[i], y_test[i])\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 2-dimensional, but 3 were indexed"
     ]
    }
   ],
   "source": [
    "for i in range(len(y_pred)):\n",
    "    print(X_test[i,:,-1], y_pred[i], y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Square Error (RMSE): 45.51650170511881\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "# Compute RMSE\n",
    "rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"Root Mean Square Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/saianoopavunuri/Documents/cs_projects/flight_delay_prediction/flight-delay-prediction/analysis/lstm.ipynb Cell 15\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/saianoopavunuri/Documents/cs_projects/flight_delay_prediction/flight-delay-prediction/analysis/lstm.ipynb#X40sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39m# X, y = create_sequences(features.values, window_size)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/saianoopavunuri/Documents/cs_projects/flight_delay_prediction/flight-delay-prediction/analysis/lstm.ipynb#X40sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m y1 \u001b[39m=\u001b[39m temp[\u001b[39m'\u001b[39m\u001b[39mDEP_DELAY\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues[window_size:]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/saianoopavunuri/Documents/cs_projects/flight_delay_prediction/flight-delay-prediction/analysis/lstm.ipynb#X40sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m X1 \u001b[39m=\u001b[39m X1\u001b[39m.\u001b[39mreshape(X1\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], X1\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], features\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/saianoopavunuri/Documents/cs_projects/flight_delay_prediction/flight-delay-prediction/analysis/lstm.ipynb#X40sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39m# Append the sequences for this route to the overall X and y\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/saianoopavunuri/Documents/cs_projects/flight_delay_prediction/flight-delay-prediction/analysis/lstm.ipynb#X40sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(X1) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "# multiple routes simple model no weather\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, Conv1D\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def create_sequences(data, window_size):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size):\n",
    "        X.append(data[i:i+window_size])\n",
    "        y.append(data[i+window_size])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Using past 5 hours to predict the next hour's delay\n",
    "window_size = 8\n",
    "\n",
    "# Convert datetime to its components\n",
    "data['year'] = data['datetime'].dt.year\n",
    "data['month'] = data['datetime'].dt.month\n",
    "data['day'] = data['datetime'].dt.day\n",
    "data['hour'] = data['datetime'].dt.hour\n",
    "data['dayofweek'] = data['datetime'].dt.dayofweek  # Monday=0, Sunday=6\n",
    "\n",
    "# One-hot encode the time variables\n",
    "data = pd.get_dummies(data, columns=['month', 'day', 'hour', 'dayofweek'])\n",
    "\n",
    "\n",
    "X, y = [], []\n",
    "\n",
    "\n",
    "for route in routes:\n",
    "    origin, dest, carrier = route[0], route[1], route[2]\n",
    "    temp = data[(data['OP_CARRIER'] == carrier) & (data['ORIGIN'] == origin) & (data['DEST'] == dest)]\n",
    "    features = temp[[col for col in temp.columns if 'month_' in col or 'day_' in col or 'hour_' in col or 'dayofweek_' in col] + ['DEP_DELAY'] + ['ARR_DELAY']]\n",
    "    \n",
    "    X1, y1 = create_sequences(features.values, window_size)\n",
    "    # X, y = create_sequences(features.values, window_size)\n",
    "    y1 = temp['DEP_DELAY'].values[window_size:]\n",
    "    X1 = X1.reshape(X1.shape[0], X1.shape[1], features.shape[1])\n",
    "\n",
    "    # Append the sequences for this route to the overall X and y\n",
    "    if len(X1) > 0:\n",
    "        if len(X) == 0:\n",
    "            X = X1\n",
    "            y = y1\n",
    "        else:\n",
    "            X = np.concatenate((X, X1), axis=0)\n",
    "            y = np.concatenate((y, y1), axis=0)\n",
    "\n",
    "# Reshape X for LSTM [samples, timesteps, features]\n",
    "X = X.reshape(X.shape[0], X.shape[1], X.shape[2])\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build LSTM model with Stacked layers\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=False)) # Add return_sequences=True for stacking\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), shuffle=False)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y_true and y_pred have different number of output (71!=1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/saianoopavunuri/Documents/cs_projects/flight_delay_prediction/flight-delay-prediction/analysis/lstm.ipynb Cell 13\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/saianoopavunuri/Documents/cs_projects/flight_delay_prediction/flight-delay-prediction/analysis/lstm.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmath\u001b[39;00m \u001b[39mimport\u001b[39;00m sqrt\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/saianoopavunuri/Documents/cs_projects/flight_delay_prediction/flight-delay-prediction/analysis/lstm.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Compute RMSE\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/saianoopavunuri/Documents/cs_projects/flight_delay_prediction/flight-delay-prediction/analysis/lstm.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m rmse \u001b[39m=\u001b[39m sqrt(mean_squared_error(y_test, y_pred))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/saianoopavunuri/Documents/cs_projects/flight_delay_prediction/flight-delay-prediction/analysis/lstm.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mRoot Mean Square Error (RMSE): \u001b[39m\u001b[39m{\u001b[39;00mrmse\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:474\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[39m@validate_params\u001b[39m(\n\u001b[1;32m    405\u001b[0m     {\n\u001b[1;32m    406\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m\"\u001b[39m\u001b[39marray-like\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    415\u001b[0m     y_true, y_pred, \u001b[39m*\u001b[39m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, multioutput\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39muniform_average\u001b[39m\u001b[39m\"\u001b[39m, squared\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    416\u001b[0m ):\n\u001b[1;32m    417\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Mean squared error regression loss.\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \n\u001b[1;32m    419\u001b[0m \u001b[39m    Read more in the :ref:`User Guide <mean_squared_error>`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[39m    0.825...\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 474\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[39m=\u001b[39m _check_reg_targets(\n\u001b[1;32m    475\u001b[0m         y_true, y_pred, multioutput\n\u001b[1;32m    476\u001b[0m     )\n\u001b[1;32m    477\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    478\u001b[0m     output_errors \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39maverage((y_true \u001b[39m-\u001b[39m y_pred) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, weights\u001b[39m=\u001b[39msample_weight)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:110\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m    107\u001b[0m     y_pred \u001b[39m=\u001b[39m y_pred\u001b[39m.\u001b[39mreshape((\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m))\n\u001b[1;32m    109\u001b[0m \u001b[39mif\u001b[39;00m y_true\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m!=\u001b[39m y_pred\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]:\n\u001b[0;32m--> 110\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    111\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39my_true and y_pred have different number of output (\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m!=\u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    112\u001b[0m             y_true\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], y_pred\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[1;32m    113\u001b[0m         )\n\u001b[1;32m    114\u001b[0m     )\n\u001b[1;32m    116\u001b[0m n_outputs \u001b[39m=\u001b[39m y_true\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[1;32m    117\u001b[0m allowed_multioutput_str \u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mraw_values\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39muniform_average\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mvariance_weighted\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: y_true and y_pred have different number of output (71!=1)"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "# Compute RMSE\n",
    "rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"Root Mean Square Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "147/147 [==============================] - 3s 6ms/step - loss: 0.0041 - val_loss: 0.0023 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "147/147 [==============================] - 0s 3ms/step - loss: 0.0038 - val_loss: 0.0023 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "147/147 [==============================] - 0s 3ms/step - loss: 0.0037 - val_loss: 0.0023 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "147/147 [==============================] - 0s 3ms/step - loss: 0.0037 - val_loss: 0.0023 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "147/147 [==============================] - 0s 3ms/step - loss: 0.0037 - val_loss: 0.0023 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "147/147 [==============================] - 0s 3ms/step - loss: 0.0037 - val_loss: 0.0023 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "147/147 [==============================] - 0s 3ms/step - loss: 0.0037 - val_loss: 0.0023 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "147/147 [==============================] - 0s 3ms/step - loss: 0.0037 - val_loss: 0.0023 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 0.0037 - val_loss: 0.0023 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "147/147 [==============================] - 0s 3ms/step - loss: 0.0037 - val_loss: 0.0023 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "147/147 [==============================] - 0s 3ms/step - loss: 0.0037 - val_loss: 0.0023 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "147/147 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0023 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "147/147 [==============================] - 0s 3ms/step - loss: 0.0037 - val_loss: 0.0023 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "147/147 [==============================] - 0s 3ms/step - loss: 0.0037 - val_loss: 0.0023 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "147/147 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0023 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "147/147 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0023 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "147/147 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0023 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "147/147 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0023 - lr: 0.0010\n",
      "Epoch 19/200\n",
      " 39/147 [======>.......................] - ETA: 0s - loss: 0.0051"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/saianoopavunuri/Documents/cs_projects/flight_delay_prediction/test2.ipynb Cell 10\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/saianoopavunuri/Documents/cs_projects/flight_delay_prediction/test2.ipynb#Y135sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m reduce_lr \u001b[39m=\u001b[39m ReduceLROnPlateau(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, factor\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, min_lr\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/saianoopavunuri/Documents/cs_projects/flight_delay_prediction/test2.ipynb#Y135sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m \u001b[39m# Train model with Callbacks\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/saianoopavunuri/Documents/cs_projects/flight_delay_prediction/test2.ipynb#Y135sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m model\u001b[39m.\u001b[39mfit(X_train, y_train, epochs\u001b[39m=\u001b[39m\u001b[39m200\u001b[39m, batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m, validation_data\u001b[39m=\u001b[39m(X_test, y_test), shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, callbacks\u001b[39m=\u001b[39m[early_stopping, reduce_lr])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/saianoopavunuri/Documents/cs_projects/flight_delay_prediction/test2.ipynb#Y135sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m \u001b[39m# Predict\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/saianoopavunuri/Documents/cs_projects/flight_delay_prediction/test2.ipynb#Y135sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1776\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1777\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1781\u001b[0m ):\n\u001b[1;32m   1782\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1783\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m   1784\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1785\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    864\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    865\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    866\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m   \u001b[39mreturn\u001b[39;00m tracing_compilation\u001b[39m.\u001b[39mcall_function(\n\u001b[1;32m    868\u001b[0m       args, kwds, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_no_variable_creation_config\n\u001b[1;32m    869\u001b[0m   )\n\u001b[1;32m    870\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    872\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39mfunction\u001b[39m.\u001b[39mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1261\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1262\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1263\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inference_function\u001b[39m.\u001b[39mflat_call(args)\n\u001b[1;32m   1265\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m     args,\n\u001b[1;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1268\u001b[0m     executing_eagerly)\n\u001b[1;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflat_call\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    216\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m(\u001b[39m*\u001b[39margs)\n\u001b[1;32m    218\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    251\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 252\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mcall_function(\n\u001b[1;32m    253\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname,\n\u001b[1;32m    254\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[1;32m    255\u001b[0m         \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mflat_outputs),\n\u001b[1;32m    256\u001b[0m     )\n\u001b[1;32m    257\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    259\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m    260\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[1;32m    261\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[1;32m    262\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1478\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1479\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute(\n\u001b[1;32m   1480\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1481\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[1;32m   1482\u001b[0m       inputs\u001b[39m=\u001b[39mtensor_inputs,\n\u001b[1;32m   1483\u001b[0m       attrs\u001b[39m=\u001b[39mattrs,\n\u001b[1;32m   1484\u001b[0m       ctx\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m,\n\u001b[1;32m   1485\u001b[0m   )\n\u001b[1;32m   1486\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1487\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1488\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1489\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1494\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[39m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[39m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[39m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, core_types\u001b[39m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[39melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def create_sequences(data, window_size):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size):\n",
    "        X.append(data[i:i+window_size])\n",
    "        y.append(data[i+window_size])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Sample data loading (please ensure you have loaded your data into the 'data' variable)\n",
    "# data = pd.read_csv('your_data_path.csv')\n",
    "\n",
    "# Using past 8 hours to predict the next hour's delay\n",
    "window_size = 8\n",
    "\n",
    "# Convert datetime to its components\n",
    "data['year'] = data['datetime'].dt.year\n",
    "data['month'] = data['datetime'].dt.month\n",
    "data['day'] = data['datetime'].dt.day\n",
    "data['hour'] = data['datetime'].dt.hour\n",
    "data['dayofweek'] = data['datetime'].dt.dayofweek  # Monday=0, Sunday=6\n",
    "\n",
    "features = data[['month', 'day', 'hour', 'dayofweek', 'rain', 'snowfall', 'windspeed_100m']]\n",
    "X, y = create_sequences(features.values, window_size)\n",
    "y = data['DEP_DELAY'].values[window_size:]\n",
    "\n",
    "# Feature Standardization\n",
    "scaler_X = MinMaxScaler()\n",
    "X = scaler_X.fit_transform(X.reshape(-1, X.shape[-1])).reshape(X.shape)\n",
    "scaler_y = MinMaxScaler()\n",
    "y = scaler_y.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build LSTM model with Stacked layers\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True)) # Add return_sequences=True for stacking\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(30, return_sequences=False))  # Additional LSTM layer\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)\n",
    "\n",
    "# Train model with Callbacks\n",
    "model.fit(X_train, y_train, epochs=200, batch_size=32, validation_data=(X_test, y_test), shuffle=False, callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = scaler_y.inverse_transform(y_pred)  # Inverse scaling for predictions\n",
    "y_test = scaler_y.inverse_transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Square Error (RMSE): 42.26330723504036\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "# Compute RMSE\n",
    "y_test = scaler_y.inverse_transform(y_test)\n",
    "\n",
    "rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"Root Mean Square Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "165/165 [==============================] - 2s 5ms/step - loss: 0.0040 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 0.0036 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "165/165 [==============================] - 1s 3ms/step - loss: 0.0036 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "165/165 [==============================] - 1s 3ms/step - loss: 0.0036 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "165/165 [==============================] - 1s 3ms/step - loss: 0.0036 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "165/165 [==============================] - 1s 3ms/step - loss: 0.0035 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "165/165 [==============================] - 1s 3ms/step - loss: 0.0035 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "165/165 [==============================] - 1s 3ms/step - loss: 0.0035 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "165/165 [==============================] - 1s 3ms/step - loss: 0.0035 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "165/165 [==============================] - 1s 3ms/step - loss: 0.0035 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "165/165 [==============================] - 1s 3ms/step - loss: 0.0035 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "165/165 [==============================] - 1s 3ms/step - loss: 0.0035 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "165/165 [==============================] - 1s 3ms/step - loss: 0.0035 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "165/165 [==============================] - 1s 3ms/step - loss: 0.0035 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "165/165 [==============================] - 1s 3ms/step - loss: 0.0035 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "165/165 [==============================] - 1s 3ms/step - loss: 0.0035 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "165/165 [==============================] - 1s 3ms/step - loss: 0.0035 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "165/165 [==============================] - 1s 3ms/step - loss: 0.0035 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "165/165 [==============================] - 1s 3ms/step - loss: 0.0035 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "165/165 [==============================] - 1s 3ms/step - loss: 0.0035 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "165/165 [==============================] - 1s 3ms/step - loss: 0.0035 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "165/165 [==============================] - 1s 3ms/step - loss: 0.0035 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "165/165 [==============================] - 1s 3ms/step - loss: 0.0035 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "165/165 [==============================] - 1s 3ms/step - loss: 0.0035 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 0.0035 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 0.0035 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "165/165 [==============================] - 1s 3ms/step - loss: 0.0035 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "165/165 [==============================] - 1s 3ms/step - loss: 0.0035 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 0.0035 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "165/165 [==============================] - 1s 3ms/step - loss: 0.0035 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "165/165 [==============================] - 1s 3ms/step - loss: 0.0035 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "165/165 [==============================] - 1s 3ms/step - loss: 0.0035 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "165/165 [==============================] - 1s 3ms/step - loss: 0.0035 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "165/165 [==============================] - 1s 3ms/step - loss: 0.0035 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "165/165 [==============================] - 1s 3ms/step - loss: 0.0035 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "165/165 [==============================] - 1s 3ms/step - loss: 0.0035 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "165/165 [==============================] - 1s 3ms/step - loss: 0.0035 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "113/165 [===================>..........] - ETA: 0s - loss: 0.0035"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/saianoopavunuri/Documents/cs_projects/flight_delay_prediction/test2.ipynb Cell 12\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/saianoopavunuri/Documents/cs_projects/flight_delay_prediction/test2.ipynb#Y124sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m reduce_lr \u001b[39m=\u001b[39m ReduceLROnPlateau(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, factor\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, min_lr\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/saianoopavunuri/Documents/cs_projects/flight_delay_prediction/test2.ipynb#Y124sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m \u001b[39m# Train model with Callbacks\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/saianoopavunuri/Documents/cs_projects/flight_delay_prediction/test2.ipynb#Y124sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m model\u001b[39m.\u001b[39mfit(X_train, y_train, epochs\u001b[39m=\u001b[39m\u001b[39m200\u001b[39m, batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m, validation_data\u001b[39m=\u001b[39m(X_test, y_test), shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, callbacks\u001b[39m=\u001b[39m[early_stopping, reduce_lr])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/saianoopavunuri/Documents/cs_projects/flight_delay_prediction/test2.ipynb#Y124sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m \u001b[39m# Predict\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/saianoopavunuri/Documents/cs_projects/flight_delay_prediction/test2.ipynb#Y124sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1776\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1777\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1781\u001b[0m ):\n\u001b[1;32m   1782\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1783\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m   1784\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1785\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    864\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    865\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    866\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m   \u001b[39mreturn\u001b[39;00m tracing_compilation\u001b[39m.\u001b[39mcall_function(\n\u001b[1;32m    868\u001b[0m       args, kwds, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_no_variable_creation_config\n\u001b[1;32m    869\u001b[0m   )\n\u001b[1;32m    870\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    872\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39mfunction\u001b[39m.\u001b[39mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1261\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1262\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1263\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inference_function\u001b[39m.\u001b[39mflat_call(args)\n\u001b[1;32m   1265\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m     args,\n\u001b[1;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1268\u001b[0m     executing_eagerly)\n\u001b[1;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflat_call\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    216\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m(\u001b[39m*\u001b[39margs)\n\u001b[1;32m    218\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    251\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 252\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mcall_function(\n\u001b[1;32m    253\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname,\n\u001b[1;32m    254\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[1;32m    255\u001b[0m         \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mflat_outputs),\n\u001b[1;32m    256\u001b[0m     )\n\u001b[1;32m    257\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    259\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m    260\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[1;32m    261\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[1;32m    262\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1478\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1479\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute(\n\u001b[1;32m   1480\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1481\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[1;32m   1482\u001b[0m       inputs\u001b[39m=\u001b[39mtensor_inputs,\n\u001b[1;32m   1483\u001b[0m       attrs\u001b[39m=\u001b[39mattrs,\n\u001b[1;32m   1484\u001b[0m       ctx\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m,\n\u001b[1;32m   1485\u001b[0m   )\n\u001b[1;32m   1486\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1487\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1488\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1489\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1494\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[39m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[39m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[39m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, core_types\u001b[39m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[39melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def create_sequences(data, window_size):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size):\n",
    "        X.append(data[i:i+window_size])\n",
    "        y.append(data[i+window_size])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Sample data loading (please ensure you have loaded your data into the 'data' variable)\n",
    "# data = pd.read_csv('your_data_path.csv')\n",
    "\n",
    "# Using past 8 hours to predict the next hour's delay\n",
    "window_size = 8\n",
    "\n",
    "# Convert datetime to its components\n",
    "data['year'] = data['datetime'].dt.year\n",
    "data['month'] = data['datetime'].dt.month\n",
    "data['day'] = data['datetime'].dt.day\n",
    "data['hour'] = data['datetime'].dt.hour\n",
    "data['dayofweek'] = data['datetime'].dt.dayofweek  # Monday=0, Sunday=6\n",
    "\n",
    "features = data[['month', 'day', 'hour', 'dayofweek', 'rain', 'snowfall', 'windspeed_100m']]\n",
    "X, y = create_sequences(features.values, window_size)\n",
    "y = data['DEP_DELAY'].values[window_size:]\n",
    "\n",
    "# Feature Standardization\n",
    "scaler_X = MinMaxScaler()\n",
    "X = scaler_X.fit_transform(X.reshape(-1, X.shape[-1])).reshape(X.shape)\n",
    "scaler_y = MinMaxScaler()\n",
    "y = scaler_y.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Build LSTM model with Stacked layers\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True)) # Add return_sequences=True for stacking\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(64, return_sequences=False))  # Additional LSTM layer\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=100, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)\n",
    "\n",
    "# Train model with Callbacks\n",
    "model.fit(X_train, y_train, epochs=200, batch_size=32, validation_data=(X_test, y_test), shuffle=False, callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = scaler_y.inverse_transform(y_pred)  # Inverse scaling for predictions\n",
    "y_test = scaler_y.inverse_transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Square Error (RMSE): 27.612384856338696\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "# Compute RMSE\n",
    "rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"Root Mean Square Error (RMSE): {rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0   0   0   0]\n",
      " [229 819  23   6]\n",
      " [ 10  30   4   1]\n",
      " [  3  27   5  14]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.93      0.76      0.84      1077\n",
      "           2       0.12      0.09      0.10        45\n",
      "           3       0.67      0.29      0.40        49\n",
      "\n",
      "    accuracy                           0.71      1171\n",
      "   macro avg       0.43      0.28      0.34      1171\n",
      "weighted avg       0.89      0.71      0.79      1171\n",
      "\n",
      "\n",
      "Accuracy Score:\n",
      "0.7147736976942783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saianoopavunuri/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saianoopavunuri/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saianoopavunuri/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Sample data\n",
    "y_true = y_test\n",
    "\n",
    "# Define a function to bin the values\n",
    "def bin_values(values):\n",
    "    bins = [0, 30, 60, float('inf')]\n",
    "    labels = ['0-30', '30-60', '60+']\n",
    "    return np.digitize(values, bins=bins, right=False).astype(str)\n",
    "\n",
    "# Bin the true and predicted values\n",
    "binned_y_true = bin_values(y_true)\n",
    "binned_y_pred = bin_values(y_pred)\n",
    "\n",
    "# Calculate classification metrics\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(binned_y_true, binned_y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(binned_y_true, binned_y_pred))\n",
    "print(\"\\nAccuracy Score:\")\n",
    "print(accuracy_score(binned_y_true, binned_y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "response2 = requests.get('https://archive-api.open-meteo.com/v1/archive?latitude=33.75&longitude=-84.39&start_date=2017-01-01&end_date=2018-12-31&hourly=temperature_2m,rain,snowfall,cloudcover,windspeed_100m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather2 = response2.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_dict = {}\n",
    "from datetime import datetime\n",
    "for i, date in enumerate(weather2['hourly']['time']):\n",
    "    hour  = datetime.strptime(date, \"%Y-%m-%dT%H:%M\")\n",
    "    weather_dict[hour] = {'temperature_2m': weather2['hourly']['temperature_2m'][i],'rain': weather2['hourly']['rain'][i], 'snowfall': weather2['hourly']['snowfall'][i], 'cloudcover': weather2['hourly']['cloudcover'][i], 'windspeed_100m': weather2['hourly']['windspeed_100m'][i] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Floor the datetime to the nearest hour\n",
    "data[\"floored_datetime\"] = data[\"datetime\"].dt.floor(\"H\") + pd.Timedelta(hours=2)\n",
    "\n",
    "# Look up the weather data and add new columns to the DataFrame\n",
    "for feature in ['temperature_2m', 'rain', 'snowfall', 'cloudcover', 'windspeed_100m','precipitation']:\n",
    "    data[feature+\"_arr\" + \"_2hr\"] = data[\"floored_datetime\"].map(lambda x: weather_dict.get(x, {}).get(feature, None))\n",
    "\n",
    "# Drop the 'floored_datetime' column if not needed\n",
    "data.drop(columns=[\"floored_datetime\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'FL_DATE', 'OP_CARRIER', 'OP_CARRIER_FL_NUM', 'ORIGIN', 'DEST',\n",
       "       'CRS_DEP_TIME', 'DEP_TIME', 'DEP_DELAY', 'TAXI_OUT', 'WHEELS_OFF',\n",
       "       'WHEELS_ON', 'TAXI_IN', 'CRS_ARR_TIME', 'ARR_TIME', 'ARR_DELAY',\n",
       "       'CRS_ELAPSED_TIME', 'ACTUAL_ELAPSED_TIME', 'AIR_TIME', 'DISTANCE',\n",
       "       'tiCRS_DEP_TIMEme', 'datetime', 'temperature_2m', 'rain', 'snowfall',\n",
       "       'cloudcover', 'windspeed_100m', 'precipitation',\n",
       "       'temperature_2m_arr_2hr', 'rain_arr_2hr', 'snowfall_arr_2hr',\n",
       "       'cloudcover_arr_2hr', 'windspeed_100m_arr_2hr', 'precipitation_arr_2hr',\n",
       "       'year', 'month', 'day', 'hour', 'dayofweek'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "146/146 [==============================] - 2s 4ms/step - loss: 1442.9301 - val_loss: 1279.8098\n",
      "Epoch 2/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1417.0137 - val_loss: 1270.4115\n",
      "Epoch 3/200\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 1412.0981 - val_loss: 1263.8053\n",
      "Epoch 4/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1407.2360 - val_loss: 1258.7118\n",
      "Epoch 5/200\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 1402.2797 - val_loss: 1248.0328\n",
      "Epoch 6/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1394.9066 - val_loss: 1249.3698\n",
      "Epoch 7/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1394.8107 - val_loss: 1240.4829\n",
      "Epoch 8/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1382.7849 - val_loss: 1234.9933\n",
      "Epoch 9/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1381.3826 - val_loss: 1229.1936\n",
      "Epoch 10/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1374.5271 - val_loss: 1223.6265\n",
      "Epoch 11/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1372.6145 - val_loss: 1219.6465\n",
      "Epoch 12/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1366.4662 - val_loss: 1217.8152\n",
      "Epoch 13/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1368.4520 - val_loss: 1207.0319\n",
      "Epoch 14/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1356.7634 - val_loss: 1203.6299\n",
      "Epoch 15/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1354.2601 - val_loss: 1203.4180\n",
      "Epoch 16/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1358.9354 - val_loss: 1204.0502\n",
      "Epoch 17/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1345.7529 - val_loss: 1190.1091\n",
      "Epoch 18/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1344.5736 - val_loss: 1186.2638\n",
      "Epoch 19/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1335.1376 - val_loss: 1180.4773\n",
      "Epoch 20/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1342.0242 - val_loss: 1180.6586\n",
      "Epoch 21/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1322.7776 - val_loss: 1167.5521\n",
      "Epoch 22/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1310.9320 - val_loss: 1162.7095\n",
      "Epoch 23/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1305.9275 - val_loss: 1164.3430\n",
      "Epoch 24/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1302.6740 - val_loss: 1154.4987\n",
      "Epoch 25/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1296.2559 - val_loss: 1156.4930\n",
      "Epoch 26/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1291.0413 - val_loss: 1140.1882\n",
      "Epoch 27/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1295.8549 - val_loss: 1131.6185\n",
      "Epoch 28/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1278.0576 - val_loss: 1129.1722\n",
      "Epoch 29/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1264.1118 - val_loss: 1125.6866\n",
      "Epoch 30/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1269.3668 - val_loss: 1125.1233\n",
      "Epoch 31/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1251.8678 - val_loss: 1109.5388\n",
      "Epoch 32/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1249.1857 - val_loss: 1122.9995\n",
      "Epoch 33/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1250.7931 - val_loss: 1117.5391\n",
      "Epoch 34/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1240.5856 - val_loss: 1102.2030\n",
      "Epoch 35/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1227.5073 - val_loss: 1092.6195\n",
      "Epoch 36/200\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 1211.7421 - val_loss: 1081.6788\n",
      "Epoch 37/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1213.3279 - val_loss: 1099.7612\n",
      "Epoch 38/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1214.0367 - val_loss: 1074.4128\n",
      "Epoch 39/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1196.2588 - val_loss: 1079.2930\n",
      "Epoch 40/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1183.3512 - val_loss: 1063.5190\n",
      "Epoch 41/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1185.3513 - val_loss: 1076.6235\n",
      "Epoch 42/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1173.8046 - val_loss: 1070.1505\n",
      "Epoch 43/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1178.2028 - val_loss: 1075.6965\n",
      "Epoch 44/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1206.7523 - val_loss: 1136.7141\n",
      "Epoch 45/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1202.4105 - val_loss: 1099.8907\n",
      "Epoch 46/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1182.7689 - val_loss: 1052.1273\n",
      "Epoch 47/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1167.2274 - val_loss: 1054.6693\n",
      "Epoch 48/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1158.9443 - val_loss: 1055.0627\n",
      "Epoch 49/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1141.8516 - val_loss: 1052.1942\n",
      "Epoch 50/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1161.8813 - val_loss: 1105.0148\n",
      "Epoch 51/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1149.6620 - val_loss: 1039.2979\n",
      "Epoch 52/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1123.1248 - val_loss: 1038.2294\n",
      "Epoch 53/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1130.6924 - val_loss: 1030.3447\n",
      "Epoch 54/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1104.0293 - val_loss: 1032.3834\n",
      "Epoch 55/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1105.9580 - val_loss: 1031.3234\n",
      "Epoch 56/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1112.4579 - val_loss: 1081.1951\n",
      "Epoch 57/200\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 1107.1895 - val_loss: 1057.0688\n",
      "Epoch 58/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1151.7938 - val_loss: 1105.2814\n",
      "Epoch 59/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1146.7147 - val_loss: 1042.0244\n",
      "Epoch 60/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1089.1422 - val_loss: 1027.5002\n",
      "Epoch 61/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1081.0306 - val_loss: 1002.8943\n",
      "Epoch 62/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1074.1827 - val_loss: 1014.6941\n",
      "Epoch 63/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1079.0399 - val_loss: 1006.6234\n",
      "Epoch 64/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1066.3610 - val_loss: 1025.0751\n",
      "Epoch 65/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1047.6149 - val_loss: 1005.9243\n",
      "Epoch 66/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1044.9752 - val_loss: 1011.2817\n",
      "Epoch 67/200\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 1108.9186 - val_loss: 1012.0190\n",
      "Epoch 68/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1054.9945 - val_loss: 983.9683\n",
      "Epoch 69/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1044.6096 - val_loss: 982.3565\n",
      "Epoch 70/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1018.7850 - val_loss: 1008.5784\n",
      "Epoch 71/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1015.6580 - val_loss: 1069.3105\n",
      "Epoch 72/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1076.7623 - val_loss: 1005.7558\n",
      "Epoch 73/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1133.6056 - val_loss: 1042.1146\n",
      "Epoch 74/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1039.0709 - val_loss: 1006.8383\n",
      "Epoch 75/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1016.1967 - val_loss: 993.3903\n",
      "Epoch 76/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 993.9390 - val_loss: 988.5643\n",
      "Epoch 77/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1011.6300 - val_loss: 997.5394\n",
      "Epoch 78/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 985.4986 - val_loss: 978.8414\n",
      "Epoch 79/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 988.4640 - val_loss: 1024.1223\n",
      "Epoch 80/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1117.2117 - val_loss: 1133.0549\n",
      "Epoch 81/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1085.6620 - val_loss: 1029.3757\n",
      "Epoch 82/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 992.1684 - val_loss: 1022.0601\n",
      "Epoch 83/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1009.1483 - val_loss: 1025.4292\n",
      "Epoch 84/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 971.6105 - val_loss: 986.1607\n",
      "Epoch 85/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 998.9897 - val_loss: 1034.9200\n",
      "Epoch 86/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 956.8561 - val_loss: 1011.3110\n",
      "Epoch 87/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 933.4540 - val_loss: 1010.9659\n",
      "Epoch 88/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 919.2499 - val_loss: 1016.2873\n",
      "Epoch 89/200\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 942.6876 - val_loss: 969.0649\n",
      "Epoch 90/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 915.4465 - val_loss: 970.0075\n",
      "Epoch 91/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 918.4597 - val_loss: 998.5330\n",
      "Epoch 92/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 938.2330 - val_loss: 971.4363\n",
      "Epoch 93/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1003.7803 - val_loss: 1000.1448\n",
      "Epoch 94/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 957.6624 - val_loss: 996.3730\n",
      "Epoch 95/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 917.0267 - val_loss: 990.9100\n",
      "Epoch 96/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 898.5026 - val_loss: 979.3790\n",
      "Epoch 97/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 908.8985 - val_loss: 1103.3080\n",
      "Epoch 98/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1008.9026 - val_loss: 1027.3584\n",
      "Epoch 99/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 956.5764 - val_loss: 1090.2560\n",
      "Epoch 100/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 935.3166 - val_loss: 1004.2277\n",
      "Epoch 101/200\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 898.2991 - val_loss: 966.5901\n",
      "Epoch 102/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 891.0193 - val_loss: 1038.7981\n",
      "Epoch 103/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 868.7980 - val_loss: 964.4034\n",
      "Epoch 104/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 879.3279 - val_loss: 980.0305\n",
      "Epoch 105/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 893.8697 - val_loss: 1175.5771\n",
      "Epoch 106/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 912.2813 - val_loss: 997.8016\n",
      "Epoch 107/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 959.5891 - val_loss: 1044.7046\n",
      "Epoch 108/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 900.4310 - val_loss: 947.5055\n",
      "Epoch 109/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 832.9707 - val_loss: 1038.9579\n",
      "Epoch 110/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 869.9642 - val_loss: 994.0744\n",
      "Epoch 111/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 853.9209 - val_loss: 1010.2144\n",
      "Epoch 112/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 865.1722 - val_loss: 978.3408\n",
      "Epoch 113/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 866.5591 - val_loss: 1017.2914\n",
      "Epoch 114/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 834.9969 - val_loss: 1121.7822\n",
      "Epoch 115/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 893.4568 - val_loss: 972.5065\n",
      "Epoch 116/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 841.4028 - val_loss: 1000.4918\n",
      "Epoch 117/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1040.0347 - val_loss: 1094.3489\n",
      "Epoch 118/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 930.4280 - val_loss: 1015.7219\n",
      "Epoch 119/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 872.9537 - val_loss: 1032.6395\n",
      "Epoch 120/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 960.6542 - val_loss: 1008.7714\n",
      "Epoch 121/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 861.0366 - val_loss: 1025.6498\n",
      "Epoch 122/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 848.3237 - val_loss: 1005.1378\n",
      "Epoch 123/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 847.1888 - val_loss: 1048.9630\n",
      "Epoch 124/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 815.6484 - val_loss: 1077.5227\n",
      "Epoch 125/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 848.2275 - val_loss: 1040.3674\n",
      "Epoch 126/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1131.1108 - val_loss: 1249.6119\n",
      "Epoch 127/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1246.7450 - val_loss: 1197.4563\n",
      "Epoch 128/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1138.5433 - val_loss: 1021.7127\n",
      "Epoch 129/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 966.7672 - val_loss: 1088.5211\n",
      "Epoch 130/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 900.6757 - val_loss: 1084.0782\n",
      "Epoch 131/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 928.7562 - val_loss: 1166.0062\n",
      "Epoch 132/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 911.2352 - val_loss: 1118.4708\n",
      "Epoch 133/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 972.6046 - val_loss: 997.6816\n",
      "Epoch 134/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 838.3870 - val_loss: 1022.3849\n",
      "Epoch 135/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 813.9446 - val_loss: 990.8989\n",
      "Epoch 136/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 832.2687 - val_loss: 1075.5482\n",
      "Epoch 137/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 794.3447 - val_loss: 1070.5548\n",
      "Epoch 138/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 825.5128 - val_loss: 968.7057\n",
      "Epoch 139/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 819.6093 - val_loss: 959.1356\n",
      "Epoch 140/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 841.4748 - val_loss: 1064.2098\n",
      "Epoch 141/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 779.4882 - val_loss: 1021.4647\n",
      "Epoch 142/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 780.0075 - val_loss: 1044.9565\n",
      "Epoch 143/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 758.8403 - val_loss: 1022.8611\n",
      "Epoch 144/200\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 746.6625 - val_loss: 1047.8340\n",
      "Epoch 145/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 754.2953 - val_loss: 1139.5408\n",
      "Epoch 146/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 946.1483 - val_loss: 1008.3909\n",
      "Epoch 147/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 797.1813 - val_loss: 1125.8969\n",
      "Epoch 148/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 740.5524 - val_loss: 1039.1366\n",
      "Epoch 149/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 732.9645 - val_loss: 1023.2178\n",
      "Epoch 150/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 762.2405 - val_loss: 974.1810\n",
      "Epoch 151/200\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 781.4158 - val_loss: 1045.5975\n",
      "Epoch 152/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 950.0079 - val_loss: 1162.7468\n",
      "Epoch 153/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 857.4962 - val_loss: 1136.2605\n",
      "Epoch 154/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 862.3960 - val_loss: 1004.2332\n",
      "Epoch 155/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 999.3265 - val_loss: 1035.6305\n",
      "Epoch 156/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 939.3174 - val_loss: 1012.2979\n",
      "Epoch 157/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 837.5401 - val_loss: 1011.4670\n",
      "Epoch 158/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 755.3222 - val_loss: 1026.6309\n",
      "Epoch 159/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 845.7263 - val_loss: 1149.1250\n",
      "Epoch 160/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 794.0634 - val_loss: 934.2263\n",
      "Epoch 161/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 761.8606 - val_loss: 967.7093\n",
      "Epoch 162/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 725.8085 - val_loss: 991.6102\n",
      "Epoch 163/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 704.4971 - val_loss: 979.4016\n",
      "Epoch 164/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 710.7554 - val_loss: 1075.9956\n",
      "Epoch 165/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 722.2349 - val_loss: 990.2764\n",
      "Epoch 166/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 707.4876 - val_loss: 993.3297\n",
      "Epoch 167/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 706.1407 - val_loss: 965.7773\n",
      "Epoch 168/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 744.1148 - val_loss: 1151.6534\n",
      "Epoch 169/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 729.4871 - val_loss: 1030.8060\n",
      "Epoch 170/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 703.8162 - val_loss: 939.9838\n",
      "Epoch 171/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 681.7797 - val_loss: 1057.2245\n",
      "Epoch 172/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 748.6577 - val_loss: 1015.2647\n",
      "Epoch 173/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 882.1330 - val_loss: 1134.4222\n",
      "Epoch 174/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 884.8306 - val_loss: 1034.5468\n",
      "Epoch 175/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 866.7421 - val_loss: 972.3517\n",
      "Epoch 176/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 815.8298 - val_loss: 919.8226\n",
      "Epoch 177/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 686.6661 - val_loss: 970.6024\n",
      "Epoch 178/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 671.3446 - val_loss: 973.2730\n",
      "Epoch 179/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 674.0193 - val_loss: 972.7703\n",
      "Epoch 180/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 780.9059 - val_loss: 1275.6399\n",
      "Epoch 181/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1134.1672 - val_loss: 1297.9573\n",
      "Epoch 182/200\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 1118.7063 - val_loss: 1006.2196\n",
      "Epoch 183/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 1038.9342 - val_loss: 1201.5886\n",
      "Epoch 184/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 847.3568 - val_loss: 965.7876\n",
      "Epoch 185/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 722.1420 - val_loss: 983.2029\n",
      "Epoch 186/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 703.1450 - val_loss: 997.7688\n",
      "Epoch 187/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 861.4445 - val_loss: 990.1752\n",
      "Epoch 188/200\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 677.0287 - val_loss: 983.1097\n",
      "Epoch 189/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 685.8637 - val_loss: 1019.3164\n",
      "Epoch 190/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 651.3878 - val_loss: 1114.1624\n",
      "Epoch 191/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 652.1338 - val_loss: 941.6990\n",
      "Epoch 192/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 637.3613 - val_loss: 936.1498\n",
      "Epoch 193/200\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 656.9388 - val_loss: 1070.4004\n",
      "Epoch 194/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 681.9725 - val_loss: 994.0038\n",
      "Epoch 195/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 623.4703 - val_loss: 968.2695\n",
      "Epoch 196/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 629.3242 - val_loss: 1027.8729\n",
      "Epoch 197/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 613.3545 - val_loss: 1042.4888\n",
      "Epoch 198/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 627.0276 - val_loss: 1199.6567\n",
      "Epoch 199/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 790.0782 - val_loss: 1262.8058\n",
      "Epoch 200/200\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 716.5130 - val_loss: 1145.6287\n",
      "37/37 [==============================] - 0s 983us/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def create_sequences(data, window_size):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size):\n",
    "        X.append(data[i:i+window_size])\n",
    "        y.append(data[i+window_size])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Using past 5 hours to predict the next hour's delay\n",
    "window_size = 8\n",
    "\n",
    "# Convert datetime to its components\n",
    "data['year'] = data['datetime'].dt.year\n",
    "data['month'] = data['datetime'].dt.month\n",
    "data['day'] = data['datetime'].dt.day\n",
    "data['hour'] = data['datetime'].dt.hour\n",
    "data['dayofweek'] = data['datetime'].dt.dayofweek  # Monday=0, Sunday=6\n",
    "\n",
    "features = data[['month', 'day', 'hour', 'dayofweek', 'rain', 'snowfall', 'windspeed_100m', 'rain_arr_2hr','snowfall_arr_2hr', 'windspeed_100m_arr_2hr']]\n",
    "X, y = create_sequences(features.values, window_size)\n",
    "y = data['DEP_DELAY'].values[window_size:]\n",
    "\n",
    "# Reshape X for LSTM [samples, timesteps, features]\n",
    "X = X.reshape(X.shape[0], X.shape[1], features.shape[1])\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train, epochs=200, batch_size=32, validation_data=(X_test, y_test), shuffle=False)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Square Error (RMSE): 33.847136609376165\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "# Compute RMSE\n",
    "rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"Root Mean Square Error (RMSE): {rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>FL_DATE</th>\n",
       "      <th>OP_CARRIER</th>\n",
       "      <th>OP_CARRIER_FL_NUM</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>DEST</th>\n",
       "      <th>CRS_DEP_TIME</th>\n",
       "      <th>DEP_TIME</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>TAXI_OUT</th>\n",
       "      <th>...</th>\n",
       "      <th>rain_arr_2hr</th>\n",
       "      <th>snowfall_arr_2hr</th>\n",
       "      <th>cloudcover_arr_2hr</th>\n",
       "      <th>windspeed_100m_arr_2hr</th>\n",
       "      <th>precipitation_arr_2hr</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofweek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8463</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>DL</td>\n",
       "      <td>1827</td>\n",
       "      <td>MCO</td>\n",
       "      <td>ATL</td>\n",
       "      <td>06:30</td>\n",
       "      <td>631.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>29.5</td>\n",
       "      <td>None</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7839</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>DL</td>\n",
       "      <td>1109</td>\n",
       "      <td>MCO</td>\n",
       "      <td>ATL</td>\n",
       "      <td>08:00</td>\n",
       "      <td>800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>12.6</td>\n",
       "      <td>None</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8646</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>DL</td>\n",
       "      <td>2032</td>\n",
       "      <td>MCO</td>\n",
       "      <td>ATL</td>\n",
       "      <td>08:30</td>\n",
       "      <td>827.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>12.6</td>\n",
       "      <td>None</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8460</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>DL</td>\n",
       "      <td>1824</td>\n",
       "      <td>MCO</td>\n",
       "      <td>ATL</td>\n",
       "      <td>09:20</td>\n",
       "      <td>919.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>13.6</td>\n",
       "      <td>None</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8462</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>DL</td>\n",
       "      <td>1826</td>\n",
       "      <td>MCO</td>\n",
       "      <td>ATL</td>\n",
       "      <td>10:25</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>15.6</td>\n",
       "      <td>None</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5910</th>\n",
       "      <td>5662786</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>DL</td>\n",
       "      <td>82</td>\n",
       "      <td>MCO</td>\n",
       "      <td>ATL</td>\n",
       "      <td>12:20</td>\n",
       "      <td>1212.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>12.6</td>\n",
       "      <td>None</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5911</th>\n",
       "      <td>5663163</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>DL</td>\n",
       "      <td>1058</td>\n",
       "      <td>MCO</td>\n",
       "      <td>ATL</td>\n",
       "      <td>14:20</td>\n",
       "      <td>1419.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>8.9</td>\n",
       "      <td>None</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5909</th>\n",
       "      <td>5662782</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>DL</td>\n",
       "      <td>72</td>\n",
       "      <td>MCO</td>\n",
       "      <td>ATL</td>\n",
       "      <td>15:20</td>\n",
       "      <td>1517.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>10.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5917</th>\n",
       "      <td>5664379</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>DL</td>\n",
       "      <td>2586</td>\n",
       "      <td>MCO</td>\n",
       "      <td>ATL</td>\n",
       "      <td>16:25</td>\n",
       "      <td>1623.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>16.9</td>\n",
       "      <td>None</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5914</th>\n",
       "      <td>5664078</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>DL</td>\n",
       "      <td>2172</td>\n",
       "      <td>MCO</td>\n",
       "      <td>ATL</td>\n",
       "      <td>17:25</td>\n",
       "      <td>1723.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>15.1</td>\n",
       "      <td>None</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5821 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index     FL_DATE OP_CARRIER  OP_CARRIER_FL_NUM ORIGIN DEST  \\\n",
       "6        8463  2017-01-01         DL               1827    MCO  ATL   \n",
       "3        7839  2017-01-01         DL               1109    MCO  ATL   \n",
       "13       8646  2017-01-01         DL               2032    MCO  ATL   \n",
       "4        8460  2017-01-01         DL               1824    MCO  ATL   \n",
       "5        8462  2017-01-01         DL               1826    MCO  ATL   \n",
       "...       ...         ...        ...                ...    ...  ...   \n",
       "5910  5662786  2017-12-31         DL                 82    MCO  ATL   \n",
       "5911  5663163  2017-12-31         DL               1058    MCO  ATL   \n",
       "5909  5662782  2017-12-31         DL                 72    MCO  ATL   \n",
       "5917  5664379  2017-12-31         DL               2586    MCO  ATL   \n",
       "5914  5664078  2017-12-31         DL               2172    MCO  ATL   \n",
       "\n",
       "     CRS_DEP_TIME  DEP_TIME  DEP_DELAY  TAXI_OUT  ...  rain_arr_2hr  \\\n",
       "6           06:30     631.0        1.0       8.0  ...           1.2   \n",
       "3           08:00     800.0        0.0      14.0  ...           0.4   \n",
       "13          08:30     827.0        0.0      11.0  ...           0.4   \n",
       "4           09:20     919.0        0.0      19.0  ...           0.2   \n",
       "5           10:25    1023.0        0.0      12.0  ...           0.0   \n",
       "...           ...       ...        ...       ...  ...           ...   \n",
       "5910        12:20    1212.0        0.0      12.0  ...           0.0   \n",
       "5911        14:20    1419.0        0.0      18.0  ...           0.0   \n",
       "5909        15:20    1517.0        0.0      26.0  ...           0.0   \n",
       "5917        16:25    1623.0        0.0      14.0  ...           0.1   \n",
       "5914        17:25    1723.0        0.0      11.0  ...           0.0   \n",
       "\n",
       "      snowfall_arr_2hr  cloudcover_arr_2hr  windspeed_100m_arr_2hr  \\\n",
       "6                  0.0                 100                    29.5   \n",
       "3                  0.0                 100                    12.6   \n",
       "13                 0.0                 100                    12.6   \n",
       "4                  0.0                 100                    13.6   \n",
       "5                  0.0                 100                    15.6   \n",
       "...                ...                 ...                     ...   \n",
       "5910               0.0                 100                    12.6   \n",
       "5911               0.0                 100                     8.9   \n",
       "5909               0.0                 100                    10.0   \n",
       "5917               0.0                 100                    16.9   \n",
       "5914               0.0                 100                    15.1   \n",
       "\n",
       "      precipitation_arr_2hr  year  month  day  hour  dayofweek  \n",
       "6                      None  2017      1    1     6          6  \n",
       "3                      None  2017      1    1     8          6  \n",
       "13                     None  2017      1    1     8          6  \n",
       "4                      None  2017      1    1     9          6  \n",
       "5                      None  2017      1    1    10          6  \n",
       "...                     ...   ...    ...  ...   ...        ...  \n",
       "5910                   None  2017     12   31    12          6  \n",
       "5911                   None  2017     12   31    14          6  \n",
       "5909                   None  2017     12   31    15          6  \n",
       "5917                   None  2017     12   31    16          6  \n",
       "5914                   None  2017     12   31    17          6  \n",
       "\n",
       "[5821 rows x 39 columns]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
